{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "$$\n",
    "# Part 2: Optimization and Training\n",
    "<a id=part2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will learn how to implement optimization algorithms for deep networks. Additionally, we'll learn how to write training loops and implement a modular model trainer.\n",
    "We'll use our optimizers and training code to test a few configurations for classifying images with an MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unittest\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tvtf\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "test = unittest.TestCase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Optimization Algorithms\n",
    "<a id=part2_1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of deep learning, an optimization algorithm is some method of iteratively updating model parameters so that the loss converges toward some local minimum (which we hope will be good enough).\n",
    "\n",
    "Gradient descent-based methods are by far the most popular algorithms for optimization of neural network parameters.\n",
    "However the high-dimensional loss-surfaces we encounter in deep learning applications are highly non-convex.\n",
    "They may be riddled with local minima, saddle points, large plateaus and a host of very challenging \"terrain\" for gradient-based optimization.\n",
    "This gave rise to many different methods of performing the parameter updates based on the loss gradients,\n",
    "aiming to tackle these optimization challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic gradient-based update rule can be written as,\n",
    "\n",
    "$$\n",
    "\\vec{\\theta} \\leftarrow \\vec{\\theta} - \\eta \\nabla_{\\vec{\\theta}} L(\\vec{\\theta}; \\mathcal{D})\n",
    "$$\n",
    "\n",
    "where $\\mathcal{D} = \\left\\{ (\\vec{x}^i, \\vec{y}^i) \\right\\}_{i=1}^{M}$ is our training dataset or part of it. Specifically, if we have in total $N$ training samples, then\n",
    "- If $M=N$ this is known as regular gradient descent. If the dataset does not fit in memory the gradient of this loss becomes infeasible to compute.\n",
    "- If $M=1$, the loss is computed w.r.t. a single different sample each time. This is known as stochastic gradient descent.\n",
    "- If $1<M<N$ this is known as stochastic mini-batch gradient descent. This is the most commonly-used option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition behind gradient descent is simple: since the gradient of a multivariate function points to the direction of steepest ascent (\"uphill\"), we move in the opposite direction. A small step size $\\eta$ known as the **learning rate** is required since the gradient can only serve as a first-order linear approximation of the function's behaviour at $\\vec{\\theta}$ (recall e.g. the Taylor expansion).\n",
    "However in truth our loss surface generally has nontrivial curvature caused by a high order nonlinear dependency on\n",
    "$\\vec{\\theta}$.\n",
    "Thus taking a large step in the direction of the gradient is actually just as likely to increase the function value.\n",
    "\n",
    "<img src=\"imgs/sgd2d.png\" width=\"600\" />\n",
    "\n",
    "The idea behind the stochastic versions is that by constantly changing the samples we compute the loss with,\n",
    "we get a dynamic error surface, i.e. it's different for each set of training samples.\n",
    "This is thought to generally improve the optimization since it may help the optimizer get out of flat regions or sharp local minima since these features may disappear in the loss surface of subsequent batches. The image below illustrates this. The different lines are different 1-dimensional losses for different training set-samples.\n",
    "\n",
    "<img src=\"imgs/sgd1d.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning frameworks generally provide implementations of various gradient-based optimization algorithms.\n",
    "Here we'll implement our own optimization module from scratch, this time keeping a similar API to the PyTorch `optim` package.\n",
    "\n",
    "We define a base `Optimizer` class. An optimizer holds a set of parameter tensors (these are the trainable parameters of some model) and maintains internal state. It may be used as follows:\n",
    "- After the forward pass has been performed the optimizer's `zero_grad()` function is invoked to clear the parameter gradients computed by previous iterations.\n",
    "- After the backward pass has been performed, and gradients have been calculated for these parameters, the optimizer's `step()` function is invoked in order to update the value of each parameter based on it's gradient.\n",
    "\n",
    "The exact method of update is implementation-specific for each optimizer and may depend on its internal state. In addition, adding the regularization penalty to the gradient is handled by the optimizer since it only depends on the parameter values (and not the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the API of our `Optimizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Optimizer in module hw2.optimizers:\n",
      "\n",
      "class Optimizer(abc.ABC)\n",
      " |  Optimizer(params)\n",
      " |  \n",
      " |  Base class for optimizers.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Optimizer\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, params)\n",
      " |      :param params: A sequence of model parameters to optimize. Can be a\n",
      " |      list of (param,grad) tuples as returned by the Layers, or a list of\n",
      " |      pytorch tensors in which case the grad will be taken from them.\n",
      " |  \n",
      " |  step(self)\n",
      " |      Updates all the registered parameter values based on their gradients.\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets the gradient of the optimized parameters to zero (in place).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  params\n",
      " |      :return: A sequence of parameter tuples, each tuple containing\n",
      " |      (param_data, param_grad). The data should be updated in-place\n",
      " |      according to the grad.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset({'step'})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hw2.optimizers as optimizers\n",
    "help(optimizers.Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla SGD with Regularization\n",
    "<a id=part2_2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by implementing the simplest gradient based optimizer. The update rule will be exacly as stated above, but we'll also add a L2-regularization term to the gradient. Remember that in the **loss function**, the L2 regularization term is expressed by\n",
    "\n",
    "$$R(\\vec{\\theta}) = \\frac{1}{2}\\lambda||\\vec{\\theta}||^2_2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Complete the implementation of the `VanillaSGD` class in the `hw2/optimizers.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff=0.0\n"
     ]
    }
   ],
   "source": [
    "# Test VanillaSGD\n",
    "torch.manual_seed(42)\n",
    "p = torch.randn(500, 10)\n",
    "dp = torch.randn(*p.shape)*2\n",
    "params = [(p, dp)]\n",
    "\n",
    "vsgd = optimizers.VanillaSGD(params, learn_rate=0.5, reg=0.1)\n",
    "vsgd.step()\n",
    "\n",
    "expected_p = torch.load('tests/assets/expected_vsgd.pt')\n",
    "diff = torch.norm(p-expected_p).item()\n",
    "print(f'diff={diff}')\n",
    "test.assertLess(diff, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "<a id=part2_3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can build a model and loss function, compute their gradients and we have an optimizer, we can finally do some training!\n",
    "\n",
    "In the spirit of more modular software design, we'll implement a class that will aid us in automating the repetitive training loop code that we usually write over and over again. This will be useful for both training our `Layer`-based models and also later for training PyTorch `nn.Module`s.\n",
    "\n",
    "Here's our `Trainer` API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Trainer in module hw2.training:\n",
      "\n",
      "class Trainer(abc.ABC)\n",
      " |  Trainer(model, loss_fn, optimizer, device=None)\n",
      " |  \n",
      " |  A class abstracting the various tasks of training models.\n",
      " |  \n",
      " |  Provides methods at multiple levels of granularity:\n",
      " |  - Multiple epochs (fit)\n",
      " |  - Single epoch (train_epoch/test_epoch)\n",
      " |  - Single batch (train_batch/test_batch)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Trainer\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model, loss_fn, optimizer, device=None)\n",
      " |      Initialize the trainer.\n",
      " |      :param model: Instance of the model to train.\n",
      " |      :param loss_fn: The loss function to evaluate with.\n",
      " |      :param optimizer: The optimizer to train with.\n",
      " |      :param device: torch.device to run training on (CPU or GPU).\n",
      " |  \n",
      " |  fit(self, dl_train: torch.utils.data.dataloader.DataLoader, dl_test: torch.utils.data.dataloader.DataLoader, num_epochs, checkpoints: str = None, early_stopping: int = None, print_every=1, **kw) -> cs3600.train_results.FitResult\n",
      " |      Trains the model for multiple epochs with a given training set,\n",
      " |      and calculates validation loss over a given validation set.\n",
      " |      :param dl_train: Dataloader for the training set.\n",
      " |      :param dl_test: Dataloader for the test set.\n",
      " |      :param num_epochs: Number of epochs to train for.\n",
      " |      :param checkpoints: Whether to save model to file every time the\n",
      " |          test set accuracy improves. Should be a string containing a\n",
      " |          filename without extension.\n",
      " |      :param early_stopping: Whether to stop training early if there is no\n",
      " |          test loss improvement for this number of epochs.\n",
      " |      :param print_every: Print progress every this number of epochs.\n",
      " |      :return: A FitResult object containing train and test losses per epoch.\n",
      " |  \n",
      " |  test_batch(self, batch) -> cs3600.train_results.BatchResult\n",
      " |      Runs a single batch forward through the model and calculates loss.\n",
      " |      :param batch: A single batch of data  from a data loader (might\n",
      " |          be a tuple of data and labels or anything else depending on\n",
      " |          the underlying dataset.\n",
      " |      :return: A BatchResult containing the value of the loss function and\n",
      " |          the number of correctly classified samples in the batch.\n",
      " |  \n",
      " |  test_epoch(self, dl_test: torch.utils.data.dataloader.DataLoader, **kw) -> cs3600.train_results.EpochResult\n",
      " |      Evaluate model once over a test set (single epoch).\n",
      " |      :param dl_test: DataLoader for the test set.\n",
      " |      :param kw: Keyword args supported by _foreach_batch.\n",
      " |      :return: An EpochResult for the epoch.\n",
      " |  \n",
      " |  train_batch(self, batch) -> cs3600.train_results.BatchResult\n",
      " |      Runs a single batch forward through the model, calculates loss,\n",
      " |      preforms back-propagation and uses the optimizer to update weights.\n",
      " |      :param batch: A single batch of data  from a data loader (might\n",
      " |          be a tuple of data and labels or anything else depending on\n",
      " |          the underlying dataset.\n",
      " |      :return: A BatchResult containing the value of the loss function and\n",
      " |          the number of correctly classified samples in the batch.\n",
      " |  \n",
      " |  train_epoch(self, dl_train: torch.utils.data.dataloader.DataLoader, **kw) -> cs3600.train_results.EpochResult\n",
      " |      Train once over a training set (single epoch).\n",
      " |      :param dl_train: DataLoader for the training set.\n",
      " |      :param kw: Keyword args supported by _foreach_batch.\n",
      " |      :return: An EpochResult for the epoch.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset({'test_batch', 'train_batch'})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hw2.training as training\n",
    "help(training.Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Trainer` class splits the task of training (and evaluating) models into three conceptual levels,\n",
    "- Multiple epochs - the `fit` method, which returns a `FitResult` containing losses and accuracies for all epochs.\n",
    "- Single epoch - the `train_epoch` and `test_epoch` methods, which return an `EpochResult` containing losses per batch and the single accuracy result of the epoch.\n",
    "- Single batch - the `train_batch` and `test_batch` methods, which return a `BatchResult` containing a single loss and the number of correctly classified samples in the batch.\n",
    "\n",
    "It implements the first two levels. Inheriting classes are expected to implement the single-batch level methods since these are model and/or task specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we should do in order to verify our model, gradient calculations and optimizer implementation is to try to overfit a large model (many parameters) to a small dataset (few images). This will show us that things are working properly.\n",
    "\n",
    "Let's begin by loading the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train: 50000 samples\n",
      "Test: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "ds_train = torchvision.datasets.CIFAR10(root=data_dir, download=True, train=True, transform=tvtf.ToTensor())\n",
    "ds_test = torchvision.datasets.CIFAR10(root=data_dir, download=True, train=False, transform=tvtf.ToTensor())\n",
    "\n",
    "print(f'Train: {len(ds_train)} samples')\n",
    "print(f'Test: {len(ds_test)} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement just a small part of our training logic since that's what we need right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "1. Complete the implementation of the `train_batch()` method in the `LayerTrainer` class within the `hw2/training.py` module.\n",
    "1. Update the hyperparameter values in the `part2_overfit_hp()` function in the `hw2/answers.py` module. Tweak the hyperparameter values until your model overfits a small number of samples in the code block below. You should get 100% accuracy within a few epochs.\n",
    "\n",
    "The following code block will use your custom `Layer`-based MLP implentation, custom Vanilla SGD and custom trainer to overfit the data. The classification accuracy should be 100% within a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batch (Avg. Loss 2.919, Accuracy 5.0): 100%|██████████████████████████████████████| 2/2 [00:00<00:00, 152.59it/s]\n",
      "train_batch (Avg. Loss 2.209, Accuracy 20.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 150.50it/s]\n",
      "train_batch (Avg. Loss 1.863, Accuracy 25.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 160.48it/s]\n",
      "train_batch (Avg. Loss 1.745, Accuracy 25.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 179.25it/s]\n",
      "train_batch (Avg. Loss 1.531, Accuracy 55.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 172.64it/s]\n",
      "train_batch (Avg. Loss 1.345, Accuracy 75.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 173.72it/s]\n",
      "train_batch (Avg. Loss 1.091, Accuracy 75.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 134.51it/s]\n",
      "train_batch (Avg. Loss 0.966, Accuracy 80.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 140.13it/s]\n",
      "train_batch (Avg. Loss 0.787, Accuracy 90.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 132.62it/s]\n",
      "train_batch (Avg. Loss 0.659, Accuracy 90.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 128.73it/s]\n",
      "train_batch (Avg. Loss 0.547, Accuracy 95.0): 100%|█████████████████████████████████████| 2/2 [00:00<00:00, 154.13it/s]\n",
      "train_batch (Avg. Loss 0.362, Accuracy 100.0): 100%|████████████████████████████████████| 2/2 [00:00<00:00, 139.77it/s]\n",
      "train_batch (Avg. Loss 0.271, Accuracy 100.0): 100%|████████████████████████████████████| 2/2 [00:00<00:00, 162.95it/s]\n",
      "train_batch (Avg. Loss 0.157, Accuracy 100.0): 100%|████████████████████████████████████| 2/2 [00:00<00:00, 169.94it/s]\n",
      "train_batch (Avg. Loss 0.107, Accuracy 100.0): 100%|████████████████████████████████████| 2/2 [00:00<00:00, 146.90it/s]\n",
      "train_batch (Avg. Loss 0.058, Accuracy 100.0): 100%|████████████████████████████████████| 2/2 [00:00<00:00, 174.60it/s]\n",
      "train_batch (Avg. Loss 0.043, Accuracy 100.0): 100%|████████████████████████████████████| 2/2 [00:00<00:00, 160.20it/s]\n",
      "train_batch (Avg. Loss 0.072, Accuracy 100.0): 100%|████████████████████████████████████| 2/2 [00:00<00:00, 160.83it/s]\n",
      "train_batch (Avg. Loss 0.029, Accuracy 100.0): 100%|████████████████████████████████████| 2/2 [00:00<00:00, 184.31it/s]\n",
      "train_batch (Avg. Loss 0.021, Accuracy 100.0): 100%|████████████████████████████████████| 2/2 [00:00<00:00, 162.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import hw2.layers as layers\n",
    "import hw2.answers as answers\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Overfit to a very small dataset of 20 samples\n",
    "batch_size = 10\n",
    "max_batches = 2\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=False)\n",
    "\n",
    "# Get hyperparameters\n",
    "hp = answers.part2_overfit_hp()\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Build a model and loss using our custom MLP and CE implementations\n",
    "model = layers.MLP(3*32*32, num_classes=10, hidden_features=[128]*3, wstd=hp['wstd'])\n",
    "loss_fn = layers.CrossEntropyLoss()\n",
    "\n",
    "# Use our custom optimizer\n",
    "optimizer = optimizers.VanillaSGD(model.params(), learn_rate=hp['lr'], reg=hp['reg'])\n",
    "\n",
    "# Run training over small dataset multiple times\n",
    "trainer = training.LayerTrainer(model, loss_fn, optimizer)\n",
    "best_acc = 0\n",
    "for i in range(20):\n",
    "    res = trainer.train_epoch(dl_train, max_batches=max_batches)\n",
    "    best_acc = res.accuracy if res.accuracy > best_acc else best_acc\n",
    "    \n",
    "test.assertGreaterEqual(best_acc, 98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know training works, let's try to fit a model to a bit more data for a few epochs, to see how well we're doing. First, we need a function to plot the FitResults object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mplot_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_res\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcs3600\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFitResult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlog_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Plots a FitResult object.\n",
       "Creates four plots: train loss, test loss, train acc, test acc.\n",
       ":param fit_res: The fit result to plot.\n",
       ":param fig: A figure previously returned from this function. If not None,\n",
       "    plots will the added to this figure.\n",
       ":param log_loss: Whether to plot the losses in log scale.\n",
       ":param legend: What to call this FitResult in the legend.\n",
       ":return: The figure.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\mryan\\docs\\dsml_idc\\semester3\\cs3600_deeplearning\\assignments\\hw2\\cs3600\\plot.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cs3600.plot import plot_fit\n",
    "plot_fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.482, Accuracy 8.8): 100%|███████████████████████████████████| 100/100 [00:01<00:00, 91.40it/s]\n",
      "test_batch (Avg. Loss 2.327, Accuracy 11.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 248.49it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.311, Accuracy 12.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 90.41it/s]\n",
      "test_batch (Avg. Loss 2.343, Accuracy 12.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 250.45it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.314, Accuracy 15.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 91.15it/s]\n",
      "test_batch (Avg. Loss 2.297, Accuracy 16.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 247.14it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.256, Accuracy 15.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 89.36it/s]\n",
      "test_batch (Avg. Loss 2.243, Accuracy 15.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 242.65it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.223, Accuracy 17.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 90.92it/s]\n",
      "test_batch (Avg. Loss 2.215, Accuracy 20.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 248.52it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 2.195, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 90.04it/s]\n",
      "test_batch (Avg. Loss 2.193, Accuracy 20.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 248.45it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 2.166, Accuracy 20.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 88.99it/s]\n",
      "test_batch (Avg. Loss 2.152, Accuracy 21.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 245.27it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 2.128, Accuracy 21.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 88.58it/s]\n",
      "test_batch (Avg. Loss 2.122, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 244.83it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 2.111, Accuracy 20.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 87.40it/s]\n",
      "test_batch (Avg. Loss 2.115, Accuracy 20.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 240.63it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 2.092, Accuracy 22.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 86.26it/s]\n",
      "test_batch (Avg. Loss 2.089, Accuracy 23.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 232.97it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01     0.00001          NaN         NaN  0.00001     23.36\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.411, Accuracy 10.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 84.62it/s]\n",
      "test_batch (Avg. Loss 2.333, Accuracy 12.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 233.58it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.302, Accuracy 15.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 80.90it/s]\n",
      "test_batch (Avg. Loss 2.261, Accuracy 15.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 228.14it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.225, Accuracy 17.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 83.22it/s]\n",
      "test_batch (Avg. Loss 2.206, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 223.65it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.179, Accuracy 19.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 80.80it/s]\n",
      "test_batch (Avg. Loss 2.151, Accuracy 21.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 224.99it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.125, Accuracy 21.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 81.20it/s]\n",
      "test_batch (Avg. Loss 2.125, Accuracy 20.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 226.32it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 2.086, Accuracy 22.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.06it/s]\n",
      "test_batch (Avg. Loss 2.071, Accuracy 26.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 224.94it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 2.019, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.46it/s]\n",
      "test_batch (Avg. Loss 2.007, Accuracy 26.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 232.16it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.983, Accuracy 27.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.49it/s]\n",
      "test_batch (Avg. Loss 1.996, Accuracy 28.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 226.22it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.955, Accuracy 28.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 81.71it/s]\n",
      "test_batch (Avg. Loss 1.988, Accuracy 28.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 230.86it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.940, Accuracy 29.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 83.56it/s]\n",
      "test_batch (Avg. Loss 1.983, Accuracy 28.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 228.73it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01     0.00001          NaN         NaN  0.00001     23.36\n",
      "1  0.01     0.00003          NaN         NaN  0.00001     28.56\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.395, Accuracy 10.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.43it/s]\n",
      "test_batch (Avg. Loss 2.344, Accuracy 13.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 232.46it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.269, Accuracy 15.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.26it/s]\n",
      "test_batch (Avg. Loss 2.231, Accuracy 18.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 229.66it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.196, Accuracy 19.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.53it/s]\n",
      "test_batch (Avg. Loss 2.166, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 223.93it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.125, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 81.56it/s]\n",
      "test_batch (Avg. Loss 2.120, Accuracy 21.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 225.78it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.068, Accuracy 24.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 81.86it/s]\n",
      "test_batch (Avg. Loss 2.025, Accuracy 27.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 225.98it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.988, Accuracy 26.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 83.28it/s]\n",
      "test_batch (Avg. Loss 1.993, Accuracy 28.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 224.34it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.958, Accuracy 27.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 81.55it/s]\n",
      "test_batch (Avg. Loss 1.992, Accuracy 27.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 226.98it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.941, Accuracy 29.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.78it/s]\n",
      "test_batch (Avg. Loss 1.974, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 230.60it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.918, Accuracy 30.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 81.94it/s]\n",
      "test_batch (Avg. Loss 1.954, Accuracy 29.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 234.56it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.893, Accuracy 31.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 83.68it/s]\n",
      "test_batch (Avg. Loss 1.925, Accuracy 31.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 225.82it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1  0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2  0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.386, Accuracy 11.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 81.59it/s]\n",
      "test_batch (Avg. Loss 2.323, Accuracy 15.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 225.31it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.245, Accuracy 16.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.26it/s]\n",
      "test_batch (Avg. Loss 2.208, Accuracy 19.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 230.04it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.170, Accuracy 20.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 78.87it/s]\n",
      "test_batch (Avg. Loss 2.130, Accuracy 21.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 236.96it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.113, Accuracy 21.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.73it/s]\n",
      "test_batch (Avg. Loss 2.117, Accuracy 24.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 224.38it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.030, Accuracy 25.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 83.54it/s]\n",
      "test_batch (Avg. Loss 2.050, Accuracy 23.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 229.68it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.984, Accuracy 27.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 84.26it/s]\n",
      "test_batch (Avg. Loss 1.976, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 230.09it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.949, Accuracy 28.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.19it/s]\n",
      "test_batch (Avg. Loss 1.990, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 227.07it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.912, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 82.14it/s]\n",
      "test_batch (Avg. Loss 1.977, Accuracy 28.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 228.91it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.905, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 80.90it/s]\n",
      "test_batch (Avg. Loss 1.911, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 206.72it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.896, Accuracy 31.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 55.09it/s]\n",
      "test_batch (Avg. Loss 1.960, Accuracy 30.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 115.90it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1  0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2  0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3  0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.377, Accuracy 11.4): 100%|██████████████████████████████████| 100/100 [00:02<00:00, 41.66it/s]\n",
      "test_batch (Avg. Loss 2.294, Accuracy 15.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 120.32it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.227, Accuracy 17.6): 100%|██████████████████████████████████| 100/100 [00:02<00:00, 42.67it/s]\n",
      "test_batch (Avg. Loss 2.194, Accuracy 20.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 144.44it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.148, Accuracy 19.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 55.07it/s]\n",
      "test_batch (Avg. Loss 2.125, Accuracy 20.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 152.19it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.066, Accuracy 23.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 54.97it/s]\n",
      "test_batch (Avg. Loss 2.016, Accuracy 26.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 159.81it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.990, Accuracy 26.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 59.45it/s]\n",
      "test_batch (Avg. Loss 2.001, Accuracy 28.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 150.74it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.957, Accuracy 27.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 58.86it/s]\n",
      "test_batch (Avg. Loss 1.976, Accuracy 27.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.11it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.911, Accuracy 29.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.28it/s]\n",
      "test_batch (Avg. Loss 1.943, Accuracy 30.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.14it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.879, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.49it/s]\n",
      "test_batch (Avg. Loss 1.915, Accuracy 30.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.61it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.836, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.46it/s]\n",
      "test_batch (Avg. Loss 1.870, Accuracy 32.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.46it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.799, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.64it/s]\n",
      "test_batch (Avg. Loss 1.856, Accuracy 34.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 148.73it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1  0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2  0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3  0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4  0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.368, Accuracy 12.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.50it/s]\n",
      "test_batch (Avg. Loss 2.268, Accuracy 15.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 177.25it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.215, Accuracy 17.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.28it/s]\n",
      "test_batch (Avg. Loss 2.178, Accuracy 20.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 177.84it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.135, Accuracy 20.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.55it/s]\n",
      "test_batch (Avg. Loss 2.132, Accuracy 22.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.58it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.058, Accuracy 22.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.99it/s]\n",
      "test_batch (Avg. Loss 2.035, Accuracy 24.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 173.78it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.002, Accuracy 26.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.53it/s]\n",
      "test_batch (Avg. Loss 1.991, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.32it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.971, Accuracy 27.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.01it/s]\n",
      "test_batch (Avg. Loss 1.982, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.18it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.930, Accuracy 29.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.27it/s]\n",
      "test_batch (Avg. Loss 1.939, Accuracy 28.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 174.82it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.894, Accuracy 29.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.15it/s]\n",
      "test_batch (Avg. Loss 1.942, Accuracy 27.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.95it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.849, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.66it/s]\n",
      "test_batch (Avg. Loss 1.874, Accuracy 32.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 156.77it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.817, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.44it/s]\n",
      "test_batch (Avg. Loss 1.863, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.97it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1  0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2  0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3  0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4  0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5  0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.358, Accuracy 12.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 59.28it/s]\n",
      "test_batch (Avg. Loss 2.251, Accuracy 16.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 175.28it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.207, Accuracy 17.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.84it/s]\n",
      "test_batch (Avg. Loss 2.161, Accuracy 21.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 174.64it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.135, Accuracy 20.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.77it/s]\n",
      "test_batch (Avg. Loss 2.119, Accuracy 24.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 163.72it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.054, Accuracy 22.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.82it/s]\n",
      "test_batch (Avg. Loss 2.026, Accuracy 24.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.86it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.983, Accuracy 27.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.85it/s]\n",
      "test_batch (Avg. Loss 2.000, Accuracy 24.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.28it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.957, Accuracy 26.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.75it/s]\n",
      "test_batch (Avg. Loss 1.971, Accuracy 26.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.92it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.917, Accuracy 29.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.14it/s]\n",
      "test_batch (Avg. Loss 1.916, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 177.17it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.862, Accuracy 32.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.07it/s]\n",
      "test_batch (Avg. Loss 1.880, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 162.50it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.826, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 59.01it/s]\n",
      "test_batch (Avg. Loss 1.872, Accuracy 32.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 186.88it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.796, Accuracy 35.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.80it/s]\n",
      "test_batch (Avg. Loss 1.839, Accuracy 34.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.93it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1  0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2  0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3  0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4  0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5  0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6  0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.351, Accuracy 13.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.99it/s]\n",
      "test_batch (Avg. Loss 2.242, Accuracy 16.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 150.02it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.196, Accuracy 18.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.92it/s]\n",
      "test_batch (Avg. Loss 2.139, Accuracy 20.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.09it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.119, Accuracy 20.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.38it/s]\n",
      "test_batch (Avg. Loss 2.066, Accuracy 24.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 166.85it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.044, Accuracy 23.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.74it/s]\n",
      "test_batch (Avg. Loss 2.048, Accuracy 23.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.23it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.993, Accuracy 26.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.27it/s]\n",
      "test_batch (Avg. Loss 2.003, Accuracy 27.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.13it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.942, Accuracy 28.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.40it/s]\n",
      "test_batch (Avg. Loss 1.944, Accuracy 28.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.83it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.897, Accuracy 30.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.66it/s]\n",
      "test_batch (Avg. Loss 1.890, Accuracy 31.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 167.77it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.847, Accuracy 32.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.21it/s]\n",
      "test_batch (Avg. Loss 1.900, Accuracy 32.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.73it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.820, Accuracy 33.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.04it/s]\n",
      "test_batch (Avg. Loss 1.852, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.88it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.786, Accuracy 34.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.52it/s]\n",
      "test_batch (Avg. Loss 1.821, Accuracy 34.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.50it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1  0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2  0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3  0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4  0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5  0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6  0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7  0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.344, Accuracy 13.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.53it/s]\n",
      "test_batch (Avg. Loss 2.237, Accuracy 17.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 183.60it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.191, Accuracy 18.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.19it/s]\n",
      "test_batch (Avg. Loss 2.143, Accuracy 20.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 190.15it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.103, Accuracy 21.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.19it/s]\n",
      "test_batch (Avg. Loss 2.050, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.47it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.016, Accuracy 25.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.94it/s]\n",
      "test_batch (Avg. Loss 2.016, Accuracy 23.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.75it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.980, Accuracy 26.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.63it/s]\n",
      "test_batch (Avg. Loss 1.974, Accuracy 29.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.42it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.926, Accuracy 28.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.95it/s]\n",
      "test_batch (Avg. Loss 1.934, Accuracy 29.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 167.61it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.883, Accuracy 30.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.45it/s]\n",
      "test_batch (Avg. Loss 1.908, Accuracy 31.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.05it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.848, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.72it/s]\n",
      "test_batch (Avg. Loss 1.886, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 148.85it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.823, Accuracy 33.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 59.56it/s]\n",
      "test_batch (Avg. Loss 1.867, Accuracy 32.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 182.89it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.791, Accuracy 35.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.10it/s]\n",
      "test_batch (Avg. Loss 1.847, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.02it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1  0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2  0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3  0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4  0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5  0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6  0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7  0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8  0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.338, Accuracy 13.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.27it/s]\n",
      "test_batch (Avg. Loss 2.233, Accuracy 17.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 182.70it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.186, Accuracy 19.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.65it/s]\n",
      "test_batch (Avg. Loss 2.134, Accuracy 22.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.10it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.101, Accuracy 21.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.87it/s]\n",
      "test_batch (Avg. Loss 2.058, Accuracy 22.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.09it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.016, Accuracy 25.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.41it/s]\n",
      "test_batch (Avg. Loss 2.005, Accuracy 25.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.88it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.973, Accuracy 24.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.99it/s]\n",
      "test_batch (Avg. Loss 1.971, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 178.01it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.925, Accuracy 29.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.83it/s]\n",
      "test_batch (Avg. Loss 1.931, Accuracy 29.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 177.42it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.881, Accuracy 31.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.37it/s]\n",
      "test_batch (Avg. Loss 1.893, Accuracy 32.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.74it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.849, Accuracy 32.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.21it/s]\n",
      "test_batch (Avg. Loss 1.869, Accuracy 31.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 182.17it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.811, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.64it/s]\n",
      "test_batch (Avg. Loss 1.890, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 164.05it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.804, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.47it/s]\n",
      "test_batch (Avg. Loss 1.824, Accuracy 36.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 163.57it/s]\n",
      "   wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0  0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1  0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2  0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3  0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4  0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5  0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6  0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7  0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8  0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9  0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.333, Accuracy 13.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.13it/s]\n",
      "test_batch (Avg. Loss 2.227, Accuracy 17.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 175.48it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.183, Accuracy 19.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.07it/s]\n",
      "test_batch (Avg. Loss 2.166, Accuracy 19.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 174.41it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.112, Accuracy 21.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.27it/s]\n",
      "test_batch (Avg. Loss 2.085, Accuracy 22.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.62it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.023, Accuracy 24.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.02it/s]\n",
      "test_batch (Avg. Loss 2.004, Accuracy 24.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.80it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.978, Accuracy 25.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.06it/s]\n",
      "test_batch (Avg. Loss 1.977, Accuracy 27.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.24it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.969, Accuracy 27.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.74it/s]\n",
      "test_batch (Avg. Loss 1.963, Accuracy 28.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 165.69it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.919, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.24it/s]\n",
      "test_batch (Avg. Loss 1.944, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.75it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.884, Accuracy 30.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.37it/s]\n",
      "test_batch (Avg. Loss 1.907, Accuracy 32.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 178.51it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.848, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.36it/s]\n",
      "test_batch (Avg. Loss 1.888, Accuracy 30.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.88it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.813, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.76it/s]\n",
      "test_batch (Avg. Loss 1.887, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.28it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.329, Accuracy 13.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.81it/s]\n",
      "test_batch (Avg. Loss 2.221, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.78it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.176, Accuracy 19.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.79it/s]\n",
      "test_batch (Avg. Loss 2.146, Accuracy 19.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.41it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.088, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.47it/s]\n",
      "test_batch (Avg. Loss 2.052, Accuracy 22.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 194.79it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.003, Accuracy 24.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.73it/s]\n",
      "test_batch (Avg. Loss 2.007, Accuracy 25.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 167.27it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.963, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.26it/s]\n",
      "test_batch (Avg. Loss 1.966, Accuracy 29.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 166.04it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.917, Accuracy 29.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.19it/s]\n",
      "test_batch (Avg. Loss 1.954, Accuracy 29.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 165.42it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.900, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.28it/s]\n",
      "test_batch (Avg. Loss 1.942, Accuracy 28.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.30it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.861, Accuracy 32.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.82it/s]\n",
      "test_batch (Avg. Loss 1.908, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.49it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.835, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.32it/s]\n",
      "test_batch (Avg. Loss 1.914, Accuracy 30.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.82it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.813, Accuracy 33.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.53it/s]\n",
      "test_batch (Avg. Loss 1.864, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 178.16it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.324, Accuracy 13.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.48it/s]\n",
      "test_batch (Avg. Loss 2.214, Accuracy 19.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.93it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.167, Accuracy 18.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.48it/s]\n",
      "test_batch (Avg. Loss 2.109, Accuracy 22.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 173.66it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.064, Accuracy 23.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.68it/s]\n",
      "test_batch (Avg. Loss 2.027, Accuracy 23.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 186.07it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.981, Accuracy 25.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.95it/s]\n",
      "test_batch (Avg. Loss 2.000, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.21it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.937, Accuracy 29.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.59it/s]\n",
      "test_batch (Avg. Loss 1.976, Accuracy 27.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.28it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.903, Accuracy 29.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.71it/s]\n",
      "test_batch (Avg. Loss 1.929, Accuracy 30.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.26it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.873, Accuracy 31.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.79it/s]\n",
      "test_batch (Avg. Loss 1.913, Accuracy 31.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 183.57it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.837, Accuracy 32.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.96it/s]\n",
      "test_batch (Avg. Loss 1.902, Accuracy 31.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 175.20it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.817, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.60it/s]\n",
      "test_batch (Avg. Loss 1.867, Accuracy 33.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 164.49it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.766, Accuracy 36.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.76it/s]\n",
      "test_batch (Avg. Loss 1.810, Accuracy 35.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 178.38it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.321, Accuracy 13.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.22it/s]\n",
      "test_batch (Avg. Loss 2.212, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.08it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.160, Accuracy 19.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.44it/s]\n",
      "test_batch (Avg. Loss 2.112, Accuracy 23.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 197.62it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.035, Accuracy 24.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.58it/s]\n",
      "test_batch (Avg. Loss 2.021, Accuracy 24.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.93it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.000, Accuracy 25.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.61it/s]\n",
      "test_batch (Avg. Loss 2.020, Accuracy 25.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 178.40it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.972, Accuracy 27.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.94it/s]\n",
      "test_batch (Avg. Loss 1.983, Accuracy 28.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.41it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.922, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.39it/s]\n",
      "test_batch (Avg. Loss 1.916, Accuracy 29.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.72it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.874, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.18it/s]\n",
      "test_batch (Avg. Loss 1.932, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.73it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.846, Accuracy 32.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.61it/s]\n",
      "test_batch (Avg. Loss 1.874, Accuracy 32.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.70it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.810, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.08it/s]\n",
      "test_batch (Avg. Loss 1.861, Accuracy 33.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.14it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.790, Accuracy 34.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.23it/s]\n",
      "test_batch (Avg. Loss 1.876, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 175.60it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.318, Accuracy 14.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.05it/s]\n",
      "test_batch (Avg. Loss 2.208, Accuracy 19.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 183.56it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.151, Accuracy 20.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.85it/s]\n",
      "test_batch (Avg. Loss 2.106, Accuracy 23.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 164.95it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.025, Accuracy 24.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.04it/s]\n",
      "test_batch (Avg. Loss 2.015, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 174.94it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.979, Accuracy 27.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.27it/s]\n",
      "test_batch (Avg. Loss 2.071, Accuracy 24.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 154.29it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.964, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.94it/s]\n",
      "test_batch (Avg. Loss 1.962, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.60it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.895, Accuracy 30.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.47it/s]\n",
      "test_batch (Avg. Loss 1.898, Accuracy 31.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 167.96it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.854, Accuracy 32.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.71it/s]\n",
      "test_batch (Avg. Loss 1.891, Accuracy 32.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.80it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.812, Accuracy 33.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.15it/s]\n",
      "test_batch (Avg. Loss 1.849, Accuracy 33.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.49it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.773, Accuracy 35.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.64it/s]\n",
      "test_batch (Avg. Loss 1.822, Accuracy 34.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 157.92it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.753, Accuracy 35.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.06it/s]\n",
      "test_batch (Avg. Loss 1.800, Accuracy 36.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.98it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.316, Accuracy 13.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.49it/s]\n",
      "test_batch (Avg. Loss 2.204, Accuracy 19.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 177.86it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.147, Accuracy 20.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.30it/s]\n",
      "test_batch (Avg. Loss 2.090, Accuracy 24.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 182.22it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.021, Accuracy 25.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.26it/s]\n",
      "test_batch (Avg. Loss 2.051, Accuracy 24.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 177.73it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.950, Accuracy 28.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.39it/s]\n",
      "test_batch (Avg. Loss 1.974, Accuracy 29.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 155.54it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.942, Accuracy 28.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.29it/s]\n",
      "test_batch (Avg. Loss 1.954, Accuracy 27.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 183.46it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.904, Accuracy 30.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.22it/s]\n",
      "test_batch (Avg. Loss 1.921, Accuracy 32.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 182.12it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.860, Accuracy 33.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.03it/s]\n",
      "test_batch (Avg. Loss 1.915, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.63it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.843, Accuracy 33.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.00it/s]\n",
      "test_batch (Avg. Loss 1.878, Accuracy 31.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.85it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.818, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.63it/s]\n",
      "test_batch (Avg. Loss 1.887, Accuracy 31.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 151.83it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.810, Accuracy 34.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.25it/s]\n",
      "test_batch (Avg. Loss 1.871, Accuracy 33.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.16it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.313, Accuracy 13.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.70it/s]\n",
      "test_batch (Avg. Loss 2.202, Accuracy 19.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.78it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.142, Accuracy 20.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.30it/s]\n",
      "test_batch (Avg. Loss 2.077, Accuracy 23.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 195.09it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.023, Accuracy 25.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.47it/s]\n",
      "test_batch (Avg. Loss 2.052, Accuracy 24.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.47it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.971, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.72it/s]\n",
      "test_batch (Avg. Loss 2.048, Accuracy 26.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 160.31it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.955, Accuracy 27.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.43it/s]\n",
      "test_batch (Avg. Loss 1.956, Accuracy 29.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 175.83it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.898, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.35it/s]\n",
      "test_batch (Avg. Loss 1.958, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 182.36it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.880, Accuracy 31.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.39it/s]\n",
      "test_batch (Avg. Loss 1.881, Accuracy 31.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.63it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.846, Accuracy 32.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.69it/s]\n",
      "test_batch (Avg. Loss 1.900, Accuracy 32.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.48it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.808, Accuracy 34.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.66it/s]\n",
      "test_batch (Avg. Loss 1.877, Accuracy 32.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 165.40it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.776, Accuracy 35.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.10it/s]\n",
      "test_batch (Avg. Loss 1.845, Accuracy 34.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.72it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.00001     34.68\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.310, Accuracy 13.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.22it/s]\n",
      "test_batch (Avg. Loss 2.198, Accuracy 20.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 164.41it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.140, Accuracy 19.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.30it/s]\n",
      "test_batch (Avg. Loss 2.089, Accuracy 23.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 183.56it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.025, Accuracy 25.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.99it/s]\n",
      "test_batch (Avg. Loss 2.014, Accuracy 23.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.96it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.958, Accuracy 27.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.33it/s]\n",
      "test_batch (Avg. Loss 1.964, Accuracy 26.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.93it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.923, Accuracy 28.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.77it/s]\n",
      "test_batch (Avg. Loss 1.950, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 178.61it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.876, Accuracy 31.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.97it/s]\n",
      "test_batch (Avg. Loss 1.922, Accuracy 30.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.79it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.858, Accuracy 32.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.41it/s]\n",
      "test_batch (Avg. Loss 1.917, Accuracy 31.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.33it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.832, Accuracy 34.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.30it/s]\n",
      "test_batch (Avg. Loss 1.893, Accuracy 34.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 147.23it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.795, Accuracy 33.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.59it/s]\n",
      "test_batch (Avg. Loss 1.854, Accuracy 33.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.81it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.752, Accuracy 36.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.24it/s]\n",
      "test_batch (Avg. Loss 1.832, Accuracy 35.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.93it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.00001     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.00001     35.48\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.308, Accuracy 14.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.72it/s]\n",
      "test_batch (Avg. Loss 2.193, Accuracy 21.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.28it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.136, Accuracy 20.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.35it/s]\n",
      "test_batch (Avg. Loss 2.092, Accuracy 23.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.85it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.031, Accuracy 24.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 59.93it/s]\n",
      "test_batch (Avg. Loss 2.021, Accuracy 27.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.38it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.988, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.40it/s]\n",
      "test_batch (Avg. Loss 1.973, Accuracy 27.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.01it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.943, Accuracy 29.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.21it/s]\n",
      "test_batch (Avg. Loss 1.927, Accuracy 30.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.46it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.870, Accuracy 31.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.62it/s]\n",
      "test_batch (Avg. Loss 1.894, Accuracy 31.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 163.42it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.817, Accuracy 33.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.83it/s]\n",
      "test_batch (Avg. Loss 1.850, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 190.56it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.790, Accuracy 35.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.50it/s]\n",
      "test_batch (Avg. Loss 1.847, Accuracy 33.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 166.33it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.775, Accuracy 36.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.98it/s]\n",
      "test_batch (Avg. Loss 1.860, Accuracy 34.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 182.12it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.764, Accuracy 37.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.75it/s]\n",
      "test_batch (Avg. Loss 1.843, Accuracy 33.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.11it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.00001     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.00001     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.00001     34.64\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.305, Accuracy 14.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.43it/s]\n",
      "test_batch (Avg. Loss 2.191, Accuracy 20.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 186.11it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.138, Accuracy 19.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.67it/s]\n",
      "test_batch (Avg. Loss 2.097, Accuracy 23.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.77it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.033, Accuracy 24.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.04it/s]\n",
      "test_batch (Avg. Loss 2.015, Accuracy 24.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.36it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.985, Accuracy 25.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.34it/s]\n",
      "test_batch (Avg. Loss 2.032, Accuracy 26.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.45it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.948, Accuracy 28.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.70it/s]\n",
      "test_batch (Avg. Loss 1.975, Accuracy 26.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.94it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.895, Accuracy 31.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.01it/s]\n",
      "test_batch (Avg. Loss 1.964, Accuracy 29.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 192.93it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.843, Accuracy 31.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.65it/s]\n",
      "test_batch (Avg. Loss 1.893, Accuracy 32.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 162.88it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.832, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.20it/s]\n",
      "test_batch (Avg. Loss 1.896, Accuracy 32.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 165.50it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.806, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.89it/s]\n",
      "test_batch (Avg. Loss 1.877, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.42it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.792, Accuracy 34.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.76it/s]\n",
      "test_batch (Avg. Loss 1.865, Accuracy 31.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 160.57it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.00001     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.00001     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.00001     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.00001     33.12\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.304, Accuracy 14.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.50it/s]\n",
      "test_batch (Avg. Loss 2.195, Accuracy 20.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.24it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.136, Accuracy 19.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.18it/s]\n",
      "test_batch (Avg. Loss 2.101, Accuracy 20.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.72it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.035, Accuracy 25.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.29it/s]\n",
      "test_batch (Avg. Loss 2.050, Accuracy 23.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.47it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.977, Accuracy 26.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.74it/s]\n",
      "test_batch (Avg. Loss 1.963, Accuracy 26.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.77it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.915, Accuracy 28.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.24it/s]\n",
      "test_batch (Avg. Loss 1.967, Accuracy 28.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 174.60it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.899, Accuracy 29.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.03it/s]\n",
      "test_batch (Avg. Loss 1.925, Accuracy 30.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 183.49it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.877, Accuracy 30.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.18it/s]\n",
      "test_batch (Avg. Loss 1.931, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.87it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.843, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.65it/s]\n",
      "test_batch (Avg. Loss 1.903, Accuracy 31.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 164.71it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.810, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.41it/s]\n",
      "test_batch (Avg. Loss 1.934, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.91it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.801, Accuracy 34.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.23it/s]\n",
      "test_batch (Avg. Loss 1.876, Accuracy 34.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 182.15it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.00001     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.00001     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.00001     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.00001     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.00001     34.44\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.302, Accuracy 14.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.17it/s]\n",
      "test_batch (Avg. Loss 2.198, Accuracy 19.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 163.47it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.141, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.13it/s]\n",
      "test_batch (Avg. Loss 2.091, Accuracy 21.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.40it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.048, Accuracy 24.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.63it/s]\n",
      "test_batch (Avg. Loss 2.020, Accuracy 23.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.57it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.994, Accuracy 25.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.89it/s]\n",
      "test_batch (Avg. Loss 1.961, Accuracy 28.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 177.15it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.925, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.73it/s]\n",
      "test_batch (Avg. Loss 1.941, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 197.27it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.865, Accuracy 31.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.17it/s]\n",
      "test_batch (Avg. Loss 1.897, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.86it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.838, Accuracy 33.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.36it/s]\n",
      "test_batch (Avg. Loss 1.863, Accuracy 32.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.72it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.838, Accuracy 32.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.09it/s]\n",
      "test_batch (Avg. Loss 1.884, Accuracy 32.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 194.54it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.830, Accuracy 34.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.53it/s]\n",
      "test_batch (Avg. Loss 1.923, Accuracy 30.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.48it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.820, Accuracy 34.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.29it/s]\n",
      "test_batch (Avg. Loss 1.894, Accuracy 34.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 194.20it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.00001     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.00001     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.00001     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.00001     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.00001     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.00001     33.96\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.301, Accuracy 15.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.81it/s]\n",
      "test_batch (Avg. Loss 2.195, Accuracy 19.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 165.38it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.137, Accuracy 19.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.76it/s]\n",
      "test_batch (Avg. Loss 2.078, Accuracy 22.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.30it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.032, Accuracy 23.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.34it/s]\n",
      "test_batch (Avg. Loss 2.092, Accuracy 21.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 199.68it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.985, Accuracy 26.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.94it/s]\n",
      "test_batch (Avg. Loss 2.010, Accuracy 26.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.02it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.909, Accuracy 29.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.93it/s]\n",
      "test_batch (Avg. Loss 1.930, Accuracy 30.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 148.00it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.870, Accuracy 31.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.49it/s]\n",
      "test_batch (Avg. Loss 1.901, Accuracy 31.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.62it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.845, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.99it/s]\n",
      "test_batch (Avg. Loss 1.918, Accuracy 30.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.14it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.803, Accuracy 34.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.02it/s]\n",
      "test_batch (Avg. Loss 1.898, Accuracy 34.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.52it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.788, Accuracy 34.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.22it/s]\n",
      "test_batch (Avg. Loss 1.866, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.87it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.777, Accuracy 35.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.42it/s]\n",
      "test_batch (Avg. Loss 1.901, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.31it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.00001     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.00001     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.00001     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.00001     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.00001     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.00001     33.96\n",
      "22  0.01    0.000459          NaN         NaN  0.00001     34.48\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.299, Accuracy 15.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.90it/s]\n",
      "test_batch (Avg. Loss 2.200, Accuracy 19.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 175.62it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.141, Accuracy 19.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.19it/s]\n",
      "test_batch (Avg. Loss 2.081, Accuracy 22.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 175.38it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.013, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.76it/s]\n",
      "test_batch (Avg. Loss 2.082, Accuracy 23.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 173.74it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.990, Accuracy 26.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.88it/s]\n",
      "test_batch (Avg. Loss 1.963, Accuracy 24.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.42it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.941, Accuracy 28.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.10it/s]\n",
      "test_batch (Avg. Loss 1.920, Accuracy 29.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.17it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.915, Accuracy 30.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.29it/s]\n",
      "test_batch (Avg. Loss 1.959, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 173.53it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.848, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.21it/s]\n",
      "test_batch (Avg. Loss 1.885, Accuracy 32.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 183.49it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.826, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.29it/s]\n",
      "test_batch (Avg. Loss 1.908, Accuracy 31.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.21it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.805, Accuracy 34.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.75it/s]\n",
      "test_batch (Avg. Loss 1.861, Accuracy 31.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 152.20it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.783, Accuracy 34.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.40it/s]\n",
      "test_batch (Avg. Loss 1.885, Accuracy 34.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.03it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.00001     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.00001     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.00001     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.00001     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.00001     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.00001     33.96\n",
      "22  0.01    0.000459          NaN         NaN  0.00001     34.48\n",
      "23  0.01    0.000480          NaN         NaN  0.00001     34.40\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.297, Accuracy 15.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.75it/s]\n",
      "test_batch (Avg. Loss 2.203, Accuracy 19.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.37it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.144, Accuracy 19.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.05it/s]\n",
      "test_batch (Avg. Loss 2.071, Accuracy 23.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.70it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.024, Accuracy 24.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.75it/s]\n",
      "test_batch (Avg. Loss 2.063, Accuracy 22.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.44it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.982, Accuracy 25.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.44it/s]\n",
      "test_batch (Avg. Loss 2.014, Accuracy 24.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 163.50it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.907, Accuracy 29.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.55it/s]\n",
      "test_batch (Avg. Loss 1.894, Accuracy 32.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 190.38it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.894, Accuracy 31.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.25it/s]\n",
      "test_batch (Avg. Loss 1.911, Accuracy 29.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.02it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.867, Accuracy 32.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.71it/s]\n",
      "test_batch (Avg. Loss 1.915, Accuracy 32.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.80it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.876, Accuracy 31.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.52it/s]\n",
      "test_batch (Avg. Loss 1.953, Accuracy 28.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 162.31it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.836, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.53it/s]\n",
      "test_batch (Avg. Loss 1.885, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.24it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.792, Accuracy 36.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.96it/s]\n",
      "test_batch (Avg. Loss 1.894, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.54it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop      reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.00001     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.00001     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.00001     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.00001     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.00001     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.00001     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.00001     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.00001     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.00001     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.00001     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.00001     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.00001     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.00001     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.00001     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.00001     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.00001     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.00001     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.00001     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.00001     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.00001     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.00001     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.00001     33.96\n",
      "22  0.01    0.000459          NaN         NaN  0.00001     34.48\n",
      "23  0.01    0.000480          NaN         NaN  0.00001     34.40\n",
      "24  0.01    0.000500          NaN         NaN  0.00001     32.48\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.482, Accuracy 8.8): 100%|███████████████████████████████████| 100/100 [00:01<00:00, 66.95it/s]\n",
      "test_batch (Avg. Loss 2.327, Accuracy 11.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.01it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.311, Accuracy 12.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.19it/s]\n",
      "test_batch (Avg. Loss 2.343, Accuracy 12.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.66it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.314, Accuracy 15.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 59.88it/s]\n",
      "test_batch (Avg. Loss 2.297, Accuracy 16.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.15it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.256, Accuracy 15.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.77it/s]\n",
      "test_batch (Avg. Loss 2.243, Accuracy 15.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.66it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.223, Accuracy 17.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.58it/s]\n",
      "test_batch (Avg. Loss 2.214, Accuracy 20.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.06it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 2.194, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.80it/s]\n",
      "test_batch (Avg. Loss 2.192, Accuracy 20.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.98it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 2.165, Accuracy 20.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.41it/s]\n",
      "test_batch (Avg. Loss 2.152, Accuracy 21.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 166.44it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 2.128, Accuracy 21.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.10it/s]\n",
      "test_batch (Avg. Loss 2.122, Accuracy 22.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.27it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 2.111, Accuracy 21.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.71it/s]\n",
      "test_batch (Avg. Loss 2.115, Accuracy 20.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 173.94it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 2.092, Accuracy 22.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.53it/s]\n",
      "test_batch (Avg. Loss 2.089, Accuracy 23.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 182.74it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.000010     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.000010     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.000010     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.000010     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.000010     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.000010     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.000010     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.000010     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.000010     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.000010     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.000010     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.000010     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.000010     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.000010     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.000010     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.000010     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.000010     33.96\n",
      "22  0.01    0.000459          NaN         NaN  0.000010     34.48\n",
      "23  0.01    0.000480          NaN         NaN  0.000010     34.40\n",
      "24  0.01    0.000500          NaN         NaN  0.000010     32.48\n",
      "25  0.01    0.000010          NaN         NaN  0.000029     23.20\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.411, Accuracy 10.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.25it/s]\n",
      "test_batch (Avg. Loss 2.333, Accuracy 12.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.56it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.302, Accuracy 15.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.75it/s]\n",
      "test_batch (Avg. Loss 2.261, Accuracy 15.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 164.39it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.225, Accuracy 17.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.53it/s]\n",
      "test_batch (Avg. Loss 2.206, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.21it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.179, Accuracy 19.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.81it/s]\n",
      "test_batch (Avg. Loss 2.151, Accuracy 21.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 178.15it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.125, Accuracy 20.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.22it/s]\n",
      "test_batch (Avg. Loss 2.125, Accuracy 20.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 183.93it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 2.086, Accuracy 22.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.92it/s]\n",
      "test_batch (Avg. Loss 2.071, Accuracy 25.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 195.74it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 2.019, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.72it/s]\n",
      "test_batch (Avg. Loss 2.007, Accuracy 26.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.29it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.984, Accuracy 27.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.36it/s]\n",
      "test_batch (Avg. Loss 1.995, Accuracy 28.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.40it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.956, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.68it/s]\n",
      "test_batch (Avg. Loss 1.991, Accuracy 28.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 174.55it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.940, Accuracy 29.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.73it/s]\n",
      "test_batch (Avg. Loss 1.979, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.86it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.000010     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.000010     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.000010     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.000010     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.000010     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.000010     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.000010     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.000010     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.000010     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.000010     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.000010     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.000010     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.000010     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.000010     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.000010     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.000010     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.000010     33.96\n",
      "22  0.01    0.000459          NaN         NaN  0.000010     34.48\n",
      "23  0.01    0.000480          NaN         NaN  0.000010     34.40\n",
      "24  0.01    0.000500          NaN         NaN  0.000010     32.48\n",
      "25  0.01    0.000010          NaN         NaN  0.000029     23.20\n",
      "26  0.01    0.000030          NaN         NaN  0.000029     28.44\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.395, Accuracy 10.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.48it/s]\n",
      "test_batch (Avg. Loss 2.344, Accuracy 13.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 154.31it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.269, Accuracy 15.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.12it/s]\n",
      "test_batch (Avg. Loss 2.231, Accuracy 18.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 190.61it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.196, Accuracy 18.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.50it/s]\n",
      "test_batch (Avg. Loss 2.166, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 174.96it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.125, Accuracy 21.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.96it/s]\n",
      "test_batch (Avg. Loss 2.120, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 190.71it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.068, Accuracy 24.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.67it/s]\n",
      "test_batch (Avg. Loss 2.024, Accuracy 27.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.77it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.988, Accuracy 26.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.99it/s]\n",
      "test_batch (Avg. Loss 1.994, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 193.54it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.960, Accuracy 27.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.40it/s]\n",
      "test_batch (Avg. Loss 1.995, Accuracy 27.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 167.93it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.944, Accuracy 29.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.96it/s]\n",
      "test_batch (Avg. Loss 1.977, Accuracy 28.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.16it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.918, Accuracy 30.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.14it/s]\n",
      "test_batch (Avg. Loss 1.959, Accuracy 29.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 192.69it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.892, Accuracy 31.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.06it/s]\n",
      "test_batch (Avg. Loss 1.935, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 154.36it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.000010     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.000010     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.000010     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.000010     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.000010     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.000010     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.000010     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.000010     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.000010     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.000010     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.000010     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.000010     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.000010     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.000010     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.000010     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.000010     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.000010     33.96\n",
      "22  0.01    0.000459          NaN         NaN  0.000010     34.48\n",
      "23  0.01    0.000480          NaN         NaN  0.000010     34.40\n",
      "24  0.01    0.000500          NaN         NaN  0.000010     32.48\n",
      "25  0.01    0.000010          NaN         NaN  0.000029     23.20\n",
      "26  0.01    0.000030          NaN         NaN  0.000029     28.44\n",
      "27  0.01    0.000051          NaN         NaN  0.000029     30.60\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.386, Accuracy 11.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.41it/s]\n",
      "test_batch (Avg. Loss 2.323, Accuracy 15.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.93it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.245, Accuracy 16.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.91it/s]\n",
      "test_batch (Avg. Loss 2.208, Accuracy 19.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.81it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.171, Accuracy 20.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.86it/s]\n",
      "test_batch (Avg. Loss 2.130, Accuracy 21.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.13it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.114, Accuracy 21.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.39it/s]\n",
      "test_batch (Avg. Loss 2.118, Accuracy 24.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.08it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.031, Accuracy 25.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.23it/s]\n",
      "test_batch (Avg. Loss 2.050, Accuracy 23.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.01it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.984, Accuracy 27.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.97it/s]\n",
      "test_batch (Avg. Loss 1.980, Accuracy 27.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 175.02it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.950, Accuracy 28.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.57it/s]\n",
      "test_batch (Avg. Loss 1.989, Accuracy 28.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.68it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.911, Accuracy 30.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.70it/s]\n",
      "test_batch (Avg. Loss 1.972, Accuracy 28.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.93it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.910, Accuracy 30.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.27it/s]\n",
      "test_batch (Avg. Loss 1.918, Accuracy 31.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.57it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.884, Accuracy 32.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.72it/s]\n",
      "test_batch (Avg. Loss 1.950, Accuracy 30.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.90it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.000010     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.000010     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.000010     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.000010     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.000010     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.000010     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.000010     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.000010     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.000010     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.000010     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.000010     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.000010     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.000010     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.000010     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.000010     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.000010     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.000010     33.96\n",
      "22  0.01    0.000459          NaN         NaN  0.000010     34.48\n",
      "23  0.01    0.000480          NaN         NaN  0.000010     34.40\n",
      "24  0.01    0.000500          NaN         NaN  0.000010     32.48\n",
      "25  0.01    0.000010          NaN         NaN  0.000029     23.20\n",
      "26  0.01    0.000030          NaN         NaN  0.000029     28.44\n",
      "27  0.01    0.000051          NaN         NaN  0.000029     30.60\n",
      "28  0.01    0.000071          NaN         NaN  0.000029     31.64\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.377, Accuracy 11.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.10it/s]\n",
      "test_batch (Avg. Loss 2.294, Accuracy 15.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.51it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.227, Accuracy 17.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.32it/s]\n",
      "test_batch (Avg. Loss 2.194, Accuracy 20.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.83it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.147, Accuracy 19.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.17it/s]\n",
      "test_batch (Avg. Loss 2.125, Accuracy 21.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.09it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.066, Accuracy 23.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.22it/s]\n",
      "test_batch (Avg. Loss 2.016, Accuracy 26.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 186.10it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.990, Accuracy 26.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.84it/s]\n",
      "test_batch (Avg. Loss 2.000, Accuracy 27.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.50it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.961, Accuracy 27.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.50it/s]\n",
      "test_batch (Avg. Loss 1.989, Accuracy 26.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.06it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.921, Accuracy 29.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.63it/s]\n",
      "test_batch (Avg. Loss 1.947, Accuracy 31.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.47it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.894, Accuracy 30.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.46it/s]\n",
      "test_batch (Avg. Loss 1.942, Accuracy 29.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.86it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.859, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.75it/s]\n",
      "test_batch (Avg. Loss 1.889, Accuracy 30.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 196.76it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.821, Accuracy 33.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.71it/s]\n",
      "test_batch (Avg. Loss 1.882, Accuracy 32.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 195.40it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.000010     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.000010     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.000010     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.000010     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.000010     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.000010     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.000010     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.000010     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.000010     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.000010     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.000010     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.000010     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.000010     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.000010     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.000010     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.000010     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.000010     33.96\n",
      "22  0.01    0.000459          NaN         NaN  0.000010     34.48\n",
      "23  0.01    0.000480          NaN         NaN  0.000010     34.40\n",
      "24  0.01    0.000500          NaN         NaN  0.000010     32.48\n",
      "25  0.01    0.000010          NaN         NaN  0.000029     23.20\n",
      "26  0.01    0.000030          NaN         NaN  0.000029     28.44\n",
      "27  0.01    0.000051          NaN         NaN  0.000029     30.60\n",
      "28  0.01    0.000071          NaN         NaN  0.000029     31.64\n",
      "29  0.01    0.000092          NaN         NaN  0.000029     32.08\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.368, Accuracy 12.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.55it/s]\n",
      "test_batch (Avg. Loss 2.268, Accuracy 15.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 190.15it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.215, Accuracy 17.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.09it/s]\n",
      "test_batch (Avg. Loss 2.178, Accuracy 20.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.20it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.135, Accuracy 20.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.72it/s]\n",
      "test_batch (Avg. Loss 2.132, Accuracy 22.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.53it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.057, Accuracy 21.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.90it/s]\n",
      "test_batch (Avg. Loss 2.033, Accuracy 23.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.36it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.002, Accuracy 26.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.55it/s]\n",
      "test_batch (Avg. Loss 1.991, Accuracy 25.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.48it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.970, Accuracy 27.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.16it/s]\n",
      "test_batch (Avg. Loss 1.974, Accuracy 28.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.03it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.928, Accuracy 29.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.99it/s]\n",
      "test_batch (Avg. Loss 1.949, Accuracy 26.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.46it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.890, Accuracy 29.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.55it/s]\n",
      "test_batch (Avg. Loss 1.929, Accuracy 27.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.07it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.851, Accuracy 32.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.40it/s]\n",
      "test_batch (Avg. Loss 1.886, Accuracy 31.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.93it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.831, Accuracy 33.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.25it/s]\n",
      "test_batch (Avg. Loss 1.887, Accuracy 32.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 178.15it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "5   0.01    0.000112          NaN         NaN  0.000010     33.88\n",
      "6   0.01    0.000132          NaN         NaN  0.000010     34.92\n",
      "7   0.01    0.000153          NaN         NaN  0.000010     34.72\n",
      "8   0.01    0.000173          NaN         NaN  0.000010     34.16\n",
      "9   0.01    0.000194          NaN         NaN  0.000010     36.16\n",
      "10  0.01    0.000214          NaN         NaN  0.000010     33.12\n",
      "11  0.01    0.000235          NaN         NaN  0.000010     33.80\n",
      "12  0.01    0.000255          NaN         NaN  0.000010     35.44\n",
      "13  0.01    0.000275          NaN         NaN  0.000010     33.36\n",
      "14  0.01    0.000296          NaN         NaN  0.000010     36.52\n",
      "15  0.01    0.000316          NaN         NaN  0.000010     33.32\n",
      "16  0.01    0.000337          NaN         NaN  0.000010     34.68\n",
      "17  0.01    0.000357          NaN         NaN  0.000010     35.48\n",
      "18  0.01    0.000378          NaN         NaN  0.000010     34.64\n",
      "19  0.01    0.000398          NaN         NaN  0.000010     33.12\n",
      "20  0.01    0.000418          NaN         NaN  0.000010     34.44\n",
      "21  0.01    0.000439          NaN         NaN  0.000010     33.96\n",
      "22  0.01    0.000459          NaN         NaN  0.000010     34.48\n",
      "23  0.01    0.000480          NaN         NaN  0.000010     34.40\n",
      "24  0.01    0.000500          NaN         NaN  0.000010     32.48\n",
      "25  0.01    0.000010          NaN         NaN  0.000029     23.20\n",
      "26  0.01    0.000030          NaN         NaN  0.000029     28.44\n",
      "27  0.01    0.000051          NaN         NaN  0.000029     30.60\n",
      "28  0.01    0.000071          NaN         NaN  0.000029     31.64\n",
      "29  0.01    0.000092          NaN         NaN  0.000029     32.08\n",
      "30  0.01    0.000112          NaN         NaN  0.000029     32.60\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.358, Accuracy 12.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.88it/s]\n",
      "test_batch (Avg. Loss 2.251, Accuracy 16.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 192.29it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.207, Accuracy 17.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.51it/s]\n",
      "test_batch (Avg. Loss 2.161, Accuracy 21.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.90it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.135, Accuracy 20.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.48it/s]\n",
      "test_batch (Avg. Loss 2.118, Accuracy 24.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 195.33it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.053, Accuracy 22.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.34it/s]\n",
      "test_batch (Avg. Loss 2.028, Accuracy 24.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.08it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.985, Accuracy 27.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.68it/s]\n",
      "test_batch (Avg. Loss 2.001, Accuracy 25.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.89it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.960, Accuracy 26.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.20it/s]\n",
      "test_batch (Avg. Loss 1.986, Accuracy 25.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.70it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.921, Accuracy 28.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.99it/s]\n",
      "test_batch (Avg. Loss 1.914, Accuracy 30.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.22it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.869, Accuracy 32.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.96it/s]\n",
      "test_batch (Avg. Loss 1.891, Accuracy 31.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.57it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "test_batch (Avg. Loss 2.227, Accuracy 17.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 166.93it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.183, Accuracy 19.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.03it/s]\n",
      "test_batch (Avg. Loss 2.165, Accuracy 19.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 175.14it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.111, Accuracy 21.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.21it/s]\n",
      "test_batch (Avg. Loss 2.083, Accuracy 22.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 196.75it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.023, Accuracy 24.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.51it/s]\n",
      "test_batch (Avg. Loss 1.998, Accuracy 24.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.63it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.975, Accuracy 26.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.52it/s]\n",
      "test_batch (Avg. Loss 1.974, Accuracy 28.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.11it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.964, Accuracy 26.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.82it/s]\n",
      "test_batch (Avg. Loss 1.965, Accuracy 27.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 190.60it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.931, Accuracy 28.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.10it/s]\n",
      "test_batch (Avg. Loss 1.958, Accuracy 29.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 192.07it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.873, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.72it/s]\n",
      "test_batch (Avg. Loss 1.930, Accuracy 28.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.26it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.851, Accuracy 31.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.32it/s]\n",
      "test_batch (Avg. Loss 1.902, Accuracy 31.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.62it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.824, Accuracy 33.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.79it/s]\n",
      "test_batch (Avg. Loss 1.855, Accuracy 34.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.32it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..   ...         ...          ...         ...       ...       ...\n",
      "56  0.01    0.000132          NaN         NaN  0.000048     34.60\n",
      "57  0.01    0.000153          NaN         NaN  0.000048     34.56\n",
      "58  0.01    0.000173          NaN         NaN  0.000048     33.40\n",
      "59  0.01    0.000194          NaN         NaN  0.000048     33.32\n",
      "60  0.01    0.000214          NaN         NaN  0.000048     34.36\n",
      "\n",
      "[61 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.329, Accuracy 13.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.11it/s]\n",
      "test_batch (Avg. Loss 2.221, Accuracy 18.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.46it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.176, Accuracy 19.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.51it/s]\n",
      "test_batch (Avg. Loss 2.147, Accuracy 19.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.41it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.088, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.52it/s]\n",
      "test_batch (Avg. Loss 2.047, Accuracy 23.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 172.49it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.007, Accuracy 24.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.83it/s]\n",
      "test_batch (Avg. Loss 2.024, Accuracy 24.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.62it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.975, Accuracy 27.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.37it/s]\n",
      "test_batch (Avg. Loss 1.959, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.59it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.922, Accuracy 28.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.20it/s]\n",
      "test_batch (Avg. Loss 1.952, Accuracy 28.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.16it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.895, Accuracy 31.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.19it/s]\n",
      "test_batch (Avg. Loss 1.894, Accuracy 31.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.72it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.845, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.96it/s]\n",
      "test_batch (Avg. Loss 1.890, Accuracy 33.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 194.95it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.818, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.06it/s]\n",
      "test_batch (Avg. Loss 1.853, Accuracy 33.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 198.51it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.807, Accuracy 34.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.31it/s]\n",
      "test_batch (Avg. Loss 1.851, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 201.71it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..   ...         ...          ...         ...       ...       ...\n",
      "57  0.01    0.000153          NaN         NaN  0.000048     34.56\n",
      "58  0.01    0.000173          NaN         NaN  0.000048     33.40\n",
      "59  0.01    0.000194          NaN         NaN  0.000048     33.32\n",
      "60  0.01    0.000214          NaN         NaN  0.000048     34.36\n",
      "61  0.01    0.000235          NaN         NaN  0.000048     33.56\n",
      "\n",
      "[62 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.324, Accuracy 13.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.91it/s]\n",
      "test_batch (Avg. Loss 2.214, Accuracy 19.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.76it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.167, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.46it/s]\n",
      "test_batch (Avg. Loss 2.110, Accuracy 23.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 197.76it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.066, Accuracy 23.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.39it/s]\n",
      "test_batch (Avg. Loss 2.030, Accuracy 22.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 196.61it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.980, Accuracy 25.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.87it/s]\n",
      "test_batch (Avg. Loss 2.023, Accuracy 24.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 156.21it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.946, Accuracy 28.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.67it/s]\n",
      "test_batch (Avg. Loss 1.971, Accuracy 28.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 170.67it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.902, Accuracy 29.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.06it/s]\n",
      "test_batch (Avg. Loss 1.922, Accuracy 30.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.32it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.863, Accuracy 32.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.87it/s]\n",
      "test_batch (Avg. Loss 1.901, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.68it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.848, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.65it/s]\n",
      "test_batch (Avg. Loss 1.907, Accuracy 30.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 196.99it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.814, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.26it/s]\n",
      "test_batch (Avg. Loss 1.854, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.54it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.795, Accuracy 34.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.47it/s]\n",
      "train_batch (Avg. Loss 2.035, Accuracy 24.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.98it/s]\n",
      "test_batch (Avg. Loss 2.052, Accuracy 22.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 150.54it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.978, Accuracy 25.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 57.52it/s]\n",
      "test_batch (Avg. Loss 1.945, Accuracy 27.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 151.30it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.905, Accuracy 28.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.48it/s]\n",
      "test_batch (Avg. Loss 1.956, Accuracy 30.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 144.17it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.878, Accuracy 30.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.17it/s]\n",
      "test_batch (Avg. Loss 1.872, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.28it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.847, Accuracy 33.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.33it/s]\n",
      "test_batch (Avg. Loss 1.914, Accuracy 33.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 198.04it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.813, Accuracy 34.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.30it/s]\n",
      "test_batch (Avg. Loss 1.874, Accuracy 32.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 168.55it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.803, Accuracy 34.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.78it/s]\n",
      "test_batch (Avg. Loss 1.875, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 206.21it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.788, Accuracy 35.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.62it/s]\n",
      "test_batch (Avg. Loss 1.899, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 200.98it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..   ...         ...          ...         ...       ...       ...\n",
      "66  0.01    0.000337          NaN         NaN  0.000048     34.84\n",
      "67  0.01    0.000357          NaN         NaN  0.000048     34.64\n",
      "68  0.01    0.000378          NaN         NaN  0.000048     34.88\n",
      "69  0.01    0.000398          NaN         NaN  0.000048     33.76\n",
      "70  0.01    0.000418          NaN         NaN  0.000048     33.80\n",
      "\n",
      "[71 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.302, Accuracy 14.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.73it/s]\n",
      "test_batch (Avg. Loss 2.197, Accuracy 19.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 200.21it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.140, Accuracy 18.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.97it/s]\n",
      "test_batch (Avg. Loss 2.090, Accuracy 21.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 205.49it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.048, Accuracy 23.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.98it/s]\n",
      "test_batch (Avg. Loss 2.027, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 181.73it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.995, Accuracy 24.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 58.80it/s]\n",
      "test_batch (Avg. Loss 1.974, Accuracy 27.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 164.26it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.919, Accuracy 28.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.79it/s]\n",
      "test_batch (Avg. Loss 1.981, Accuracy 27.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 193.71it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.890, Accuracy 30.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.92it/s]\n",
      "test_batch (Avg. Loss 1.991, Accuracy 26.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 167.72it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.858, Accuracy 31.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.67it/s]\n",
      "test_batch (Avg. Loss 1.917, Accuracy 29.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.02it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.802, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.14it/s]\n",
      "test_batch (Avg. Loss 1.878, Accuracy 32.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 194.29it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.780, Accuracy 34.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.85it/s]\n",
      "test_batch (Avg. Loss 1.853, Accuracy 35.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 164.94it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.759, Accuracy 36.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.05it/s]\n",
      "test_batch (Avg. Loss 1.850, Accuracy 35.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 144.11it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..   ...         ...          ...         ...       ...       ...\n",
      "67  0.01    0.000357          NaN         NaN  0.000048     34.64\n",
      "68  0.01    0.000378          NaN         NaN  0.000048     34.88\n",
      "69  0.01    0.000398          NaN         NaN  0.000048     33.76\n",
      "70  0.01    0.000418          NaN         NaN  0.000048     33.80\n",
      "71  0.01    0.000439          NaN         NaN  0.000048     35.60\n",
      "\n",
      "[72 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.301, Accuracy 15.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.32it/s]\n",
      "test_batch (Avg. Loss 2.195, Accuracy 19.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 192.52it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.140, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.88it/s]\n",
      "test_batch (Avg. Loss 2.087, Accuracy 21.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 163.45it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.032, Accuracy 24.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.76it/s]\n",
      "test_batch (Avg. Loss 2.098, Accuracy 21.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.56it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.999, Accuracy 26.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.64it/s]\n",
      "test_batch (Avg. Loss 2.007, Accuracy 26.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 201.24it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.950, Accuracy 28.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.74it/s]\n",
      "test_batch (Avg. Loss 1.950, Accuracy 30.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.74it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.911, Accuracy 30.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.53it/s]\n",
      "test_batch (Avg. Loss 1.952, Accuracy 30.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 190.84it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.867, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.52it/s]\n",
      "test_batch (Avg. Loss 1.883, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.65it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.820, Accuracy 33.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.49it/s]\n",
      "train_batch (Avg. Loss 1.798, Accuracy 34.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.07it/s]\n",
      "test_batch (Avg. Loss 1.840, Accuracy 34.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 196.15it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..   ...         ...          ...         ...       ...       ...\n",
      "77  0.01    0.000051          NaN         NaN  0.000067     30.32\n",
      "78  0.01    0.000071          NaN         NaN  0.000067     31.36\n",
      "79  0.01    0.000092          NaN         NaN  0.000067     34.72\n",
      "80  0.01    0.000112          NaN         NaN  0.000067     32.72\n",
      "81  0.01    0.000132          NaN         NaN  0.000067     34.80\n",
      "\n",
      "[82 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.351, Accuracy 13.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.21it/s]\n",
      "test_batch (Avg. Loss 2.242, Accuracy 16.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 196.60it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.196, Accuracy 18.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.62it/s]\n",
      "test_batch (Avg. Loss 2.138, Accuracy 20.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 196.62it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.118, Accuracy 20.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.99it/s]\n",
      "test_batch (Avg. Loss 2.061, Accuracy 24.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.99it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.049, Accuracy 23.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.60it/s]\n",
      "test_batch (Avg. Loss 2.068, Accuracy 23.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 196.51it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.995, Accuracy 27.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.54it/s]\n",
      "test_batch (Avg. Loss 2.027, Accuracy 26.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 162.09it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.946, Accuracy 27.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.12it/s]\n",
      "test_batch (Avg. Loss 1.962, Accuracy 26.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 156.28it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.904, Accuracy 29.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.32it/s]\n",
      "test_batch (Avg. Loss 1.893, Accuracy 31.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 206.68it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.851, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.67it/s]\n",
      "test_batch (Avg. Loss 1.895, Accuracy 32.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 188.29it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.810, Accuracy 34.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.54it/s]\n",
      "test_batch (Avg. Loss 1.859, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 155.42it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.773, Accuracy 35.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.67it/s]\n",
      "test_batch (Avg. Loss 1.846, Accuracy 34.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 193.38it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..   ...         ...          ...         ...       ...       ...\n",
      "78  0.01    0.000071          NaN         NaN  0.000067     31.36\n",
      "79  0.01    0.000092          NaN         NaN  0.000067     34.72\n",
      "80  0.01    0.000112          NaN         NaN  0.000067     32.72\n",
      "81  0.01    0.000132          NaN         NaN  0.000067     34.80\n",
      "82  0.01    0.000153          NaN         NaN  0.000067     34.56\n",
      "\n",
      "[83 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.344, Accuracy 13.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.26it/s]\n",
      "test_batch (Avg. Loss 2.237, Accuracy 17.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 192.68it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.191, Accuracy 18.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.86it/s]\n",
      "test_batch (Avg. Loss 2.143, Accuracy 20.1): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 176.24it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.103, Accuracy 21.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.00it/s]\n",
      "test_batch (Avg. Loss 2.048, Accuracy 25.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.48it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.017, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.74it/s]\n",
      "test_batch (Avg. Loss 2.012, Accuracy 24.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 158.20it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.978, Accuracy 26.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.83it/s]\n",
      "test_batch (Avg. Loss 1.984, Accuracy 27.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.78it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.925, Accuracy 28.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.49it/s]\n",
      "test_batch (Avg. Loss 1.925, Accuracy 30.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 191.60it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.880, Accuracy 31.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.03it/s]\n",
      "test_batch (Avg. Loss 1.916, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.36it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.853, Accuracy 32.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.89it/s]\n",
      "test_batch (Avg. Loss 1.894, Accuracy 30.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 174.04it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.820, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.99it/s]\n",
      "test_batch (Avg. Loss 1.862, Accuracy 33.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 192.02it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.789, Accuracy 34.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.29it/s]\n",
      "test_batch (Avg. Loss 1.827, Accuracy 34.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.58it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..   ...         ...          ...         ...       ...       ...\n",
      "79  0.01    0.000092          NaN         NaN  0.000067     34.72\n",
      "80  0.01    0.000112          NaN         NaN  0.000067     32.72\n",
      "81  0.01    0.000132          NaN         NaN  0.000067     34.80\n",
      "82  0.01    0.000153          NaN         NaN  0.000067     34.56\n",
      "83  0.01    0.000173          NaN         NaN  0.000067     34.88\n",
      "\n",
      "[84 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.338, Accuracy 13.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.54it/s]\n",
      "test_batch (Avg. Loss 2.233, Accuracy 17.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 197.15it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.187, Accuracy 19.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.19it/s]\n",
      "test_batch (Avg. Loss 2.134, Accuracy 21.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 169.94it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.101, Accuracy 21.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.13it/s]\n",
      "test_batch (Avg. Loss 2.060, Accuracy 22.6): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 187.47it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.012, Accuracy 25.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.45it/s]\n",
      "test_batch (Avg. Loss 1.993, Accuracy 26.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 199.77it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.971, Accuracy 25.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.35it/s]\n",
      "test_batch (Avg. Loss 1.987, Accuracy 26.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 197.97it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.929, Accuracy 28.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 64.86it/s]\n",
      "test_batch (Avg. Loss 1.948, Accuracy 29.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 178.70it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.901, Accuracy 30.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.31it/s]\n",
      "test_batch (Avg. Loss 1.922, Accuracy 30.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 195.41it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.856, Accuracy 32.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.60it/s]\n",
      "test_batch (Avg. Loss 1.884, Accuracy 31.8): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 185.33it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.766, Accuracy 34.6): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 61.17it/s]\n",
      "test_batch (Avg. Loss 1.824, Accuracy 35.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 171.53it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.737, Accuracy 37.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.50it/s]\n",
      "test_batch (Avg. Loss 1.839, Accuracy 34.5): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 180.96it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..   ...         ...          ...         ...       ...       ...\n",
      "90  0.01    0.000316          NaN         NaN  0.000067     35.64\n",
      "91  0.01    0.000337          NaN         NaN  0.000067     34.44\n",
      "92  0.01    0.000357          NaN         NaN  0.000067     34.08\n",
      "93  0.01    0.000378          NaN         NaN  0.000067     35.20\n",
      "94  0.01    0.000398          NaN         NaN  0.000067     34.96\n",
      "\n",
      "[95 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.304, Accuracy 14.2): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.08it/s]\n",
      "test_batch (Avg. Loss 2.194, Accuracy 20.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 196.10it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.137, Accuracy 19.1): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.14it/s]\n",
      "test_batch (Avg. Loss 2.101, Accuracy 21.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.19it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.036, Accuracy 24.9): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.82it/s]\n",
      "test_batch (Avg. Loss 2.042, Accuracy 23.4): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 142.57it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.973, Accuracy 26.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 52.05it/s]\n",
      "test_batch (Avg. Loss 1.981, Accuracy 25.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 186.07it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.929, Accuracy 28.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 59.70it/s]\n",
      "test_batch (Avg. Loss 1.987, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 186.30it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.911, Accuracy 30.3): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 66.15it/s]\n",
      "test_batch (Avg. Loss 1.983, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 160.85it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.890, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 67.81it/s]\n",
      "test_batch (Avg. Loss 1.950, Accuracy 29.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 179.15it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.872, Accuracy 30.7): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 63.96it/s]\n",
      "test_batch (Avg. Loss 1.917, Accuracy 29.9): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 162.29it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.862, Accuracy 31.8): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 68.00it/s]\n",
      "test_batch (Avg. Loss 1.909, Accuracy 31.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 184.59it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.811, Accuracy 33.5): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 62.93it/s]\n",
      "test_batch (Avg. Loss 1.873, Accuracy 32.7): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 192.50it/s]\n",
      "    wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0   0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1   0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2   0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3   0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4   0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..   ...         ...          ...         ...       ...       ...\n",
      "91  0.01    0.000337          NaN         NaN  0.000067     34.44\n",
      "92  0.01    0.000357          NaN         NaN  0.000067     34.08\n",
      "93  0.01    0.000378          NaN         NaN  0.000067     35.20\n",
      "94  0.01    0.000398          NaN         NaN  0.000067     34.96\n",
      "95  0.01    0.000418          NaN         NaN  0.000067     32.68\n",
      "\n",
      "[96 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.302, Accuracy 14.4): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 60.59it/s]\n",
      "test_batch (Avg. Loss 2.198, Accuracy 19.3): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 189.99it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.140, Accuracy 19.0): 100%|██████████████████████████████████| 100/100 [00:01<00:00, 65.18it/s]\n",
      "test_batch (Avg. Loss 2.096, Accuracy 21.2): 100%|██████████████████████████████████| 100/100 [00:00<00:00, 198.86it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.314, Accuracy 15.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.40it/s]\n",
      "test_batch (Avg. Loss 2.297, Accuracy 16.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.60it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.256, Accuracy 15.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.94it/s]\n",
      "test_batch (Avg. Loss 2.243, Accuracy 15.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 22.01it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.223, Accuracy 17.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.37it/s]\n",
      "test_batch (Avg. Loss 2.214, Accuracy 20.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.20it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 2.195, Accuracy 18.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.06it/s]\n",
      "test_batch (Avg. Loss 2.193, Accuracy 20.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.18it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.955, Accuracy 28.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.98it/s]\n",
      "test_batch (Avg. Loss 1.989, Accuracy 28.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.89it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.939, Accuracy 29.6): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.09it/s]\n",
      "test_batch (Avg. Loss 1.980, Accuracy 27.9): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.75it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "97   0.01    0.000459          NaN         NaN  0.000067     34.68\n",
      "98   0.01    0.000480          NaN         NaN  0.000067     34.64\n",
      "99   0.01    0.000500          NaN         NaN  0.000067     34.16\n",
      "100  0.01    0.000010          NaN         NaN  0.000086     23.56\n",
      "101  0.01    0.000030          NaN         NaN  0.000086     28.32\n",
      "\n",
      "[102 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.395, Accuracy 10.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.06it/s]\n",
      "test_batch (Avg. Loss 2.344, Accuracy 13.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.56it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.269, Accuracy 15.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.13it/s]\n",
      "test_batch (Avg. Loss 2.231, Accuracy 18.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.73it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.196, Accuracy 18.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.18it/s]\n",
      "train_batch (Avg. Loss 2.386, Accuracy 11.2): 100%|██████████████████████████████████| 100/100 [00:13<00:00,  7.29it/s]\n",
      "test_batch (Avg. Loss 2.323, Accuracy 15.0): 100%|███████████████████████████████████| 100/100 [00:05<00:00, 18.83it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.245, Accuracy 16.6): 100%|██████████████████████████████████| 100/100 [00:12<00:00,  8.26it/s]\n",
      "test_batch (Avg. Loss 2.208, Accuracy 19.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.70it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.171, Accuracy 20.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.08it/s]\n",
      "test_batch (Avg. Loss 2.130, Accuracy 21.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.92it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.113, Accuracy 21.3): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.13it/s]\n",
      "test_batch (Avg. Loss 2.117, Accuracy 24.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.09it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.031, Accuracy 24.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.24it/s]\n",
      "train_batch (Avg. Loss 2.135, Accuracy 20.2): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.22it/s]\n",
      "test_batch (Avg. Loss 2.132, Accuracy 22.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.68it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.058, Accuracy 22.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.05it/s]\n",
      "test_batch (Avg. Loss 2.033, Accuracy 23.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.28it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.003, Accuracy 26.1): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.22it/s]\n",
      "test_batch (Avg. Loss 1.988, Accuracy 25.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.79it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.969, Accuracy 27.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.21it/s]\n",
      "test_batch (Avg. Loss 1.971, Accuracy 28.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.09it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.924, Accuracy 29.6): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.28it/s]\n",
      "train_batch (Avg. Loss 1.798, Accuracy 34.7): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.14it/s]\n",
      "test_batch (Avg. Loss 1.828, Accuracy 34.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.35it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "102  0.01    0.000051          NaN         NaN  0.000086     30.32\n",
      "103  0.01    0.000071          NaN         NaN  0.000086     31.20\n",
      "104  0.01    0.000092          NaN         NaN  0.000086     32.04\n",
      "105  0.01    0.000112          NaN         NaN  0.000086     33.52\n",
      "106  0.01    0.000132          NaN         NaN  0.000086     34.92\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.351, Accuracy 13.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.91it/s]\n",
      "test_batch (Avg. Loss 2.242, Accuracy 16.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.43it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.196, Accuracy 18.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.98it/s]\n",
      "test_batch (Avg. Loss 2.138, Accuracy 20.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.88it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.119, Accuracy 20.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.08it/s]\n",
      "test_batch (Avg. Loss 2.064, Accuracy 23.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.07it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "test_batch (Avg. Loss 1.938, Accuracy 27.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.26it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.882, Accuracy 30.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.99it/s]\n",
      "test_batch (Avg. Loss 1.902, Accuracy 30.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.26it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.845, Accuracy 32.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 1.894, Accuracy 31.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.53it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.819, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 1.861, Accuracy 31.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.29it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.796, Accuracy 33.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.87it/s]\n",
      "test_batch (Avg. Loss 1.859, Accuracy 33.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.66it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "104  0.01    0.000092          NaN         NaN  0.000086     32.04\n",
      "105  0.01    0.000112          NaN         NaN  0.000086     33.52\n",
      "106  0.01    0.000132          NaN         NaN  0.000086     34.92\n",
      "107  0.01    0.000153          NaN         NaN  0.000086     33.84\n",
      "108  0.01    0.000173          NaN         NaN  0.000086     33.44\n",
      "\n",
      "[109 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "test_batch (Avg. Loss 2.082, Accuracy 22.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.53it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.019, Accuracy 25.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.73it/s]\n",
      "test_batch (Avg. Loss 1.999, Accuracy 25.7): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.51it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.972, Accuracy 26.5): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.27it/s]\n",
      "test_batch (Avg. Loss 1.976, Accuracy 28.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.84it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.958, Accuracy 27.2): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.26it/s]\n",
      "test_batch (Avg. Loss 1.950, Accuracy 28.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.81it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.912, Accuracy 28.8): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.37it/s]\n",
      "train_batch (Avg. Loss 1.792, Accuracy 35.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.90it/s]\n",
      "test_batch (Avg. Loss 1.813, Accuracy 35.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.25it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "107  0.01    0.000153          NaN         NaN  0.000086     33.84\n",
      "108  0.01    0.000173          NaN         NaN  0.000086     33.44\n",
      "109  0.01    0.000194          NaN         NaN  0.000086     34.68\n",
      "110  0.01    0.000214          NaN         NaN  0.000086     33.40\n",
      "111  0.01    0.000235          NaN         NaN  0.000086     35.64\n",
      "\n",
      "[112 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.324, Accuracy 13.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n",
      "test_batch (Avg. Loss 2.213, Accuracy 19.3): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.23it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.167, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.93it/s]\n",
      "test_batch (Avg. Loss 2.110, Accuracy 23.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.34it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.068, Accuracy 22.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.10it/s]\n",
      "test_batch (Avg. Loss 2.029, Accuracy 22.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.28it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "test_batch (Avg. Loss 1.905, Accuracy 29.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.45it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.839, Accuracy 32.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.04it/s]\n",
      "test_batch (Avg. Loss 1.914, Accuracy 29.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.76it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.817, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.23it/s]\n",
      "test_batch (Avg. Loss 1.863, Accuracy 33.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.59it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.791, Accuracy 34.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.14it/s]\n",
      "test_batch (Avg. Loss 1.888, Accuracy 32.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.94it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "109  0.01    0.000194          NaN         NaN  0.000086     34.68\n",
      "110  0.01    0.000214          NaN         NaN  0.000086     33.40\n",
      "111  0.01    0.000235          NaN         NaN  0.000086     35.64\n",
      "112  0.01    0.000255          NaN         NaN  0.000086     34.64\n",
      "113  0.01    0.000275          NaN         NaN  0.000086     33.24\n",
      "\n",
      "[114 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.318, Accuracy 14.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.85it/s]\n",
      "test_batch (Avg. Loss 1.973, Accuracy 29.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.87it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.944, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.07it/s]\n",
      "test_batch (Avg. Loss 1.947, Accuracy 28.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.33it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.921, Accuracy 30.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.01it/s]\n",
      "test_batch (Avg. Loss 1.911, Accuracy 31.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.48it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.856, Accuracy 32.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.66it/s]\n",
      "test_batch (Avg. Loss 1.881, Accuracy 33.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.19it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "test_batch (Avg. Loss 2.197, Accuracy 20.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.27it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.141, Accuracy 19.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 2.089, Accuracy 23.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.41it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.031, Accuracy 25.1): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.14it/s]\n",
      "test_batch (Avg. Loss 2.030, Accuracy 22.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.94it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.975, Accuracy 27.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.08it/s]\n",
      "test_batch (Avg. Loss 1.957, Accuracy 27.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.67it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.934, Accuracy 28.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.95it/s]\n",
      "train_batch (Avg. Loss 1.983, Accuracy 25.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.42it/s]\n",
      "test_batch (Avg. Loss 1.999, Accuracy 26.0): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.35it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.920, Accuracy 29.3): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.23it/s]\n",
      "test_batch (Avg. Loss 1.979, Accuracy 29.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.12it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.894, Accuracy 31.5): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.23it/s]\n",
      "test_batch (Avg. Loss 1.914, Accuracy 32.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.41it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.857, Accuracy 32.5): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.27it/s]\n",
      "test_batch (Avg. Loss 1.909, Accuracy 31.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.35it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.842, Accuracy 32.0): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.10it/s]\n",
      "test_batch (Avg. Loss 1.896, Accuracy 32.3): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.56it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "test_batch (Avg. Loss 1.911, Accuracy 32.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.01it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.774, Accuracy 35.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.92it/s]\n",
      "test_batch (Avg. Loss 1.858, Accuracy 34.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.46it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "116  0.01    0.000337          NaN         NaN  0.000086     34.32\n",
      "117  0.01    0.000357          NaN         NaN  0.000086     34.24\n",
      "118  0.01    0.000378          NaN         NaN  0.000086     34.76\n",
      "119  0.01    0.000398          NaN         NaN  0.000086     33.40\n",
      "120  0.01    0.000418          NaN         NaN  0.000086     34.68\n",
      "\n",
      "[121 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.302, Accuracy 14.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "test_batch (Avg. Loss 2.198, Accuracy 19.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.77it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.140, Accuracy 18.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.88it/s]\n",
      "test_batch (Avg. Loss 2.091, Accuracy 22.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.33it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.047, Accuracy 24.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.98it/s]\n",
      "train_batch (Avg. Loss 1.945, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.71it/s]\n",
      "test_batch (Avg. Loss 1.934, Accuracy 28.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.21it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.876, Accuracy 30.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.15it/s]\n",
      "test_batch (Avg. Loss 1.911, Accuracy 30.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.38it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.859, Accuracy 31.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "test_batch (Avg. Loss 1.902, Accuracy 32.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.46it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.844, Accuracy 33.5): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.27it/s]\n",
      "test_batch (Avg. Loss 2.075, Accuracy 23.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.51it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.033, Accuracy 23.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.71it/s]\n",
      "test_batch (Avg. Loss 2.084, Accuracy 23.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 22.25it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.014, Accuracy 24.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.98it/s]\n",
      "test_batch (Avg. Loss 2.007, Accuracy 24.5): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.95it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.937, Accuracy 29.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 1.941, Accuracy 30.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.37it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.898, Accuracy 31.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.02it/s]\n",
      "train_batch (Avg. Loss 2.092, Accuracy 22.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.18it/s]\n",
      "test_batch (Avg. Loss 2.088, Accuracy 23.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.62it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "121  0.01    0.000439          NaN         NaN  0.000086     34.36\n",
      "122  0.01    0.000459          NaN         NaN  0.000086     32.76\n",
      "123  0.01    0.000480          NaN         NaN  0.000086     34.80\n",
      "124  0.01    0.000500          NaN         NaN  0.000086     33.28\n",
      "125  0.01    0.000010          NaN         NaN  0.000105     23.60\n",
      "\n",
      "[126 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.411, Accuracy 10.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.02it/s]\n",
      "test_batch (Avg. Loss 2.333, Accuracy 12.5): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.08it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.302, Accuracy 15.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.19it/s]\n",
      "test_batch (Avg. Loss 2.261, Accuracy 15.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.19it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.225, Accuracy 17.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.94it/s]\n",
      "test_batch (Avg. Loss 2.206, Accuracy 18.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.46it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "test_batch (Avg. Loss 1.974, Accuracy 28.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.60it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.919, Accuracy 30.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 1.958, Accuracy 29.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.47it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.895, Accuracy 31.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.07it/s]\n",
      "test_batch (Avg. Loss 1.933, Accuracy 31.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.74it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "123  0.01    0.000480          NaN         NaN  0.000086     34.80\n",
      "124  0.01    0.000500          NaN         NaN  0.000086     33.28\n",
      "125  0.01    0.000010          NaN         NaN  0.000105     23.60\n",
      "126  0.01    0.000030          NaN         NaN  0.000105     28.28\n",
      "127  0.01    0.000051          NaN         NaN  0.000105     31.00\n",
      "\n",
      "[128 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.386, Accuracy 11.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 2.323, Accuracy 15.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.24it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.245, Accuracy 16.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 2.208, Accuracy 19.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.23it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 1.892, Accuracy 30.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.08it/s]\n",
      "test_batch (Avg. Loss 1.947, Accuracy 27.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.98it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.873, Accuracy 31.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.06it/s]\n",
      "test_batch (Avg. Loss 1.936, Accuracy 30.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.16it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.845, Accuracy 32.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.01it/s]\n",
      "test_batch (Avg. Loss 1.914, Accuracy 31.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.53it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "125  0.01    0.000010          NaN         NaN  0.000105     23.60\n",
      "126  0.01    0.000030          NaN         NaN  0.000105     28.28\n",
      "127  0.01    0.000051          NaN         NaN  0.000105     31.00\n",
      "128  0.01    0.000071          NaN         NaN  0.000105     31.44\n",
      "129  0.01    0.000092          NaN         NaN  0.000105     31.00\n",
      "\n",
      "[130 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.368, Accuracy 12.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.90it/s]\n",
      "test_batch (Avg. Loss 2.268, Accuracy 15.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.72it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 1.923, Accuracy 28.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.98it/s]\n",
      "test_batch (Avg. Loss 1.918, Accuracy 30.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.27it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.876, Accuracy 31.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.02it/s]\n",
      "test_batch (Avg. Loss 1.921, Accuracy 30.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.19it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.837, Accuracy 32.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.95it/s]\n",
      "test_batch (Avg. Loss 1.853, Accuracy 33.3): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.23it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.785, Accuracy 35.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.01it/s]\n",
      "test_batch (Avg. Loss 1.821, Accuracy 35.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.80it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "127  0.01    0.000051          NaN         NaN  0.000105     31.00\n",
      "128  0.01    0.000071          NaN         NaN  0.000105     31.44\n",
      "129  0.01    0.000092          NaN         NaN  0.000105     31.00\n",
      "130  0.01    0.000112          NaN         NaN  0.000105     34.08\n",
      "131  0.01    0.000132          NaN         NaN  0.000105     35.64\n",
      "\n",
      "[132 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 1.841, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.71it/s]\n",
      "test_batch (Avg. Loss 1.883, Accuracy 32.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.80it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.814, Accuracy 34.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "test_batch (Avg. Loss 1.883, Accuracy 31.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.22it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.789, Accuracy 34.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.08it/s]\n",
      "test_batch (Avg. Loss 1.870, Accuracy 32.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.66it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "129  0.01    0.000092          NaN         NaN  0.000105     31.00\n",
      "130  0.01    0.000112          NaN         NaN  0.000105     34.08\n",
      "131  0.01    0.000132          NaN         NaN  0.000105     35.64\n",
      "132  0.01    0.000153          NaN         NaN  0.000105     34.32\n",
      "133  0.01    0.000173          NaN         NaN  0.000105     32.68\n",
      "\n",
      "[134 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.338, Accuracy 13.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.88it/s]\n",
      "train_batch (Avg. Loss 1.958, Accuracy 27.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.02it/s]\n",
      "test_batch (Avg. Loss 1.951, Accuracy 29.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.65it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.907, Accuracy 28.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.23it/s]\n",
      "test_batch (Avg. Loss 1.938, Accuracy 29.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.05it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.857, Accuracy 32.3): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.21it/s]\n",
      "test_batch (Avg. Loss 1.930, Accuracy 30.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.83it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.837, Accuracy 33.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.05it/s]\n",
      "test_batch (Avg. Loss 1.887, Accuracy 32.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.01it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.919, Accuracy 29.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.93it/s]\n",
      "test_batch (Avg. Loss 1.972, Accuracy 28.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.99it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.899, Accuracy 30.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.99it/s]\n",
      "test_batch (Avg. Loss 1.919, Accuracy 31.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.22it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.853, Accuracy 32.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 1.925, Accuracy 31.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.00it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.815, Accuracy 34.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.05it/s]\n",
      "test_batch (Avg. Loss 1.837, Accuracy 34.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.29it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.844, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.49it/s]\n",
      "test_batch (Avg. Loss 1.868, Accuracy 31.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.95it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.817, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n",
      "test_batch (Avg. Loss 1.857, Accuracy 33.0): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.69it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.785, Accuracy 34.8): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.14it/s]\n",
      "test_batch (Avg. Loss 1.849, Accuracy 34.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.77it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "134  0.01    0.000194          NaN         NaN  0.000105     34.52\n",
      "135  0.01    0.000214          NaN         NaN  0.000105     33.52\n",
      "136  0.01    0.000235          NaN         NaN  0.000105     34.64\n",
      "137  0.01    0.000255          NaN         NaN  0.000105     34.72\n",
      "138  0.01    0.000275          NaN         NaN  0.000105     34.60\n",
      "\n",
      "[139 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.318, Accuracy 14.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.68it/s]\n",
      "test_batch (Avg. Loss 2.208, Accuracy 19.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.85it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.151, Accuracy 20.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.85it/s]\n",
      "train_batch (Avg. Loss 1.944, Accuracy 29.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.02it/s]\n",
      "test_batch (Avg. Loss 1.956, Accuracy 29.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.23it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.889, Accuracy 30.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.89it/s]\n",
      "test_batch (Avg. Loss 1.912, Accuracy 32.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.61it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.832, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.11it/s]\n",
      "test_batch (Avg. Loss 1.889, Accuracy 32.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.19it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.831, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.05it/s]\n",
      "test_batch (Avg. Loss 1.892, Accuracy 31.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.21it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "test_batch (Avg. Loss 1.917, Accuracy 31.0): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.13it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.845, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.45it/s]\n",
      "test_batch (Avg. Loss 1.878, Accuracy 32.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.56it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.798, Accuracy 34.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.16it/s]\n",
      "test_batch (Avg. Loss 1.868, Accuracy 34.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.25it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.767, Accuracy 35.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.11it/s]\n",
      "test_batch (Avg. Loss 1.830, Accuracy 36.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.10it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "138  0.01    0.000275          NaN         NaN  0.000105     34.60\n",
      "139  0.01    0.000296          NaN         NaN  0.000105     34.80\n",
      "140  0.01    0.000316          NaN         NaN  0.000105     35.12\n",
      "141  0.01    0.000337          NaN         NaN  0.000105     34.84\n",
      "142  0.01    0.000357          NaN         NaN  0.000105     35.96\n",
      "\n",
      "[143 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.308, Accuracy 14.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.09it/s]\n",
      "test_batch (Avg. Loss 2.193, Accuracy 21.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.36it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 1.815, Accuracy 34.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "test_batch (Avg. Loss 1.841, Accuracy 34.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.61it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.791, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.61it/s]\n",
      "test_batch (Avg. Loss 1.907, Accuracy 34.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.06it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.801, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.07it/s]\n",
      "test_batch (Avg. Loss 1.823, Accuracy 35.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.32it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "141  0.01    0.000337          NaN         NaN  0.000105     34.84\n",
      "142  0.01    0.000357          NaN         NaN  0.000105     35.96\n",
      "143  0.01    0.000378          NaN         NaN  0.000105     35.48\n",
      "144  0.01    0.000398          NaN         NaN  0.000105     34.84\n",
      "145  0.01    0.000418          NaN         NaN  0.000105     35.84\n",
      "\n",
      "[146 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.302, Accuracy 14.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.79it/s]\n",
      "test_batch (Avg. Loss 1.898, Accuracy 30.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.91it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.845, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 1.878, Accuracy 34.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.58it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.811, Accuracy 34.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 1.885, Accuracy 33.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.50it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "test_batch (Avg. Loss 1.899, Accuracy 31.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.17it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.811, Accuracy 34.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 1.927, Accuracy 32.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.29it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.827, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.06it/s]\n",
      "test_batch (Avg. Loss 1.910, Accuracy 30.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.51it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.846, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:12<00:00,  7.97it/s]\n",
      "test_batch (Avg. Loss 1.875, Accuracy 32.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.71it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "144  0.01    0.000398          NaN         NaN  0.000105     34.84\n",
      "145  0.01    0.000418          NaN         NaN  0.000105     35.84\n",
      "146  0.01    0.000439          NaN         NaN  0.000105     33.32\n",
      "147  0.01    0.000459          NaN         NaN  0.000105     34.76\n",
      "148  0.01    0.000480          NaN         NaN  0.000105     32.72\n",
      "\n",
      "[149 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.297, Accuracy 15.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.53it/s]\n",
      "test_batch (Avg. Loss 2.203, Accuracy 18.9): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.54it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 1.763, Accuracy 35.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.54it/s]\n",
      "test_batch (Avg. Loss 1.827, Accuracy 35.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.61it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "145  0.01    0.000418          NaN         NaN  0.000105     35.84\n",
      "146  0.01    0.000439          NaN         NaN  0.000105     33.32\n",
      "147  0.01    0.000459          NaN         NaN  0.000105     34.76\n",
      "148  0.01    0.000480          NaN         NaN  0.000105     32.72\n",
      "149  0.01    0.000500          NaN         NaN  0.000105     35.68\n",
      "\n",
      "[150 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.482, Accuracy 8.8): 100%|███████████████████████████████████| 100/100 [00:11<00:00,  8.79it/s]\n",
      "test_batch (Avg. Loss 2.327, Accuracy 11.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.01it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.311, Accuracy 12.1): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.15it/s]\n",
      "test_batch (Avg. Loss 2.343, Accuracy 12.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.51it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.314, Accuracy 15.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 2.297, Accuracy 16.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.34it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.386, Accuracy 11.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.61it/s]\n",
      "test_batch (Avg. Loss 2.323, Accuracy 15.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.14it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.245, Accuracy 16.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.02it/s]\n",
      "test_batch (Avg. Loss 2.208, Accuracy 19.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.60it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.170, Accuracy 20.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 2.130, Accuracy 21.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.83it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.113, Accuracy 21.2): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.15it/s]\n",
      "test_batch (Avg. Loss 2.118, Accuracy 24.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.33it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.215, Accuracy 17.2): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.10it/s]\n",
      "test_batch (Avg. Loss 2.178, Accuracy 20.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.41it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.135, Accuracy 20.2): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.10it/s]\n",
      "test_batch (Avg. Loss 2.132, Accuracy 22.0): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.67it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.058, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.25it/s]\n",
      "test_batch (Avg. Loss 2.037, Accuracy 23.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.91it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 2.004, Accuracy 26.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.94it/s]\n",
      "test_batch (Avg. Loss 1.991, Accuracy 25.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.10it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 2.119, Accuracy 20.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.84it/s]\n",
      "test_batch (Avg. Loss 2.066, Accuracy 23.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.70it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.046, Accuracy 23.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.99it/s]\n",
      "test_batch (Avg. Loss 2.041, Accuracy 25.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.35it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.974, Accuracy 26.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.05it/s]\n",
      "test_batch (Avg. Loss 1.980, Accuracy 29.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.73it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.918, Accuracy 28.7): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.11it/s]\n",
      "test_batch (Avg. Loss 1.922, Accuracy 30.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.55it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.870, Accuracy 32.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.94it/s]\n",
      "test_batch (Avg. Loss 1.882, Accuracy 33.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.36it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.841, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.26it/s]\n",
      "test_batch (Avg. Loss 1.895, Accuracy 30.7): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.72it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.899, Accuracy 29.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.66it/s]\n",
      "test_batch (Avg. Loss 1.910, Accuracy 31.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.36it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.870, Accuracy 31.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.92it/s]\n",
      "test_batch (Avg. Loss 1.912, Accuracy 30.5): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.66it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.848, Accuracy 30.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 1.881, Accuracy 31.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.70it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.814, Accuracy 33.6): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.26it/s]\n",
      "test_batch (Avg. Loss 1.874, Accuracy 32.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.69it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "156  0.01    0.000132          NaN         NaN  0.000124     33.84\n",
      "157  0.01    0.000153          NaN         NaN  0.000124     35.16\n",
      "158  0.01    0.000173          NaN         NaN  0.000124     33.48\n",
      "159  0.01    0.000194          NaN         NaN  0.000124     33.56\n",
      "160  0.01    0.000214          NaN         NaN  0.000124     32.40\n",
      "\n",
      "[161 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 1.792, Accuracy 35.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.95it/s]\n",
      "test_batch (Avg. Loss 1.870, Accuracy 32.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.49it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.780, Accuracy 34.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.05it/s]\n",
      "test_batch (Avg. Loss 1.820, Accuracy 33.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.40it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "158  0.01    0.000173          NaN         NaN  0.000124     33.48\n",
      "159  0.01    0.000194          NaN         NaN  0.000124     33.56\n",
      "160  0.01    0.000214          NaN         NaN  0.000124     32.40\n",
      "161  0.01    0.000235          NaN         NaN  0.000124     34.00\n",
      "162  0.01    0.000255          NaN         NaN  0.000124     33.88\n",
      "\n",
      "[163 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 1.974, Accuracy 27.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.89it/s]\n",
      "test_batch (Avg. Loss 2.005, Accuracy 26.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.62it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.915, Accuracy 28.8): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.10it/s]\n",
      "test_batch (Avg. Loss 1.885, Accuracy 32.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.60it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.871, Accuracy 31.6): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.26it/s]\n",
      "test_batch (Avg. Loss 1.894, Accuracy 31.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.40it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.827, Accuracy 33.5): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.19it/s]\n",
      "train_batch (Avg. Loss 1.755, Accuracy 36.2): 100%|██████████████████████████████████| 100/100 [00:12<00:00,  8.09it/s]\n",
      "test_batch (Avg. Loss 1.833, Accuracy 34.9): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.14it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "161  0.01    0.000235          NaN         NaN  0.000124     34.00\n",
      "162  0.01    0.000255          NaN         NaN  0.000124     33.88\n",
      "163  0.01    0.000275          NaN         NaN  0.000124     33.80\n",
      "164  0.01    0.000296          NaN         NaN  0.000124     34.56\n",
      "165  0.01    0.000316          NaN         NaN  0.000124     34.92\n",
      "\n",
      "[166 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.313, Accuracy 13.8): 100%|██████████████████████████████████| 100/100 [00:12<00:00,  8.30it/s]\n",
      "test_batch (Avg. Loss 2.201, Accuracy 19.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.65it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.142, Accuracy 20.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.44it/s]\n",
      "test_batch (Avg. Loss 2.078, Accuracy 23.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 22.28it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.024, Accuracy 25.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.65it/s]\n",
      "test_batch (Avg. Loss 2.032, Accuracy 25.5): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 21.68it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.308, Accuracy 14.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.91it/s]\n",
      "test_batch (Avg. Loss 2.193, Accuracy 21.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.61it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.136, Accuracy 20.5): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.34it/s]\n",
      "test_batch (Avg. Loss 2.101, Accuracy 22.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.86it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.036, Accuracy 24.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.66it/s]\n",
      "test_batch (Avg. Loss 2.004, Accuracy 28.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.50it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.840, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:12<00:00,  8.26it/s]\n",
      "test_batch (Avg. Loss 1.895, Accuracy 32.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.70it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.815, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.44it/s]\n",
      "test_batch (Avg. Loss 1.872, Accuracy 32.0): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 22.84it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.790, Accuracy 36.1): 100%|██████████████████████████████████| 100/100 [00:12<00:00,  8.30it/s]\n",
      "test_batch (Avg. Loss 1.871, Accuracy 34.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.51it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.762, Accuracy 36.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.50it/s]\n",
      "test_batch (Avg. Loss 1.886, Accuracy 33.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.64it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "165  0.01    0.000316          NaN         NaN  0.000124     34.92\n",
      "166  0.01    0.000337          NaN         NaN  0.000124     31.48\n",
      "167  0.01    0.000357          NaN         NaN  0.000124     36.48\n",
      "168  0.01    0.000378          NaN         NaN  0.000124     33.44\n",
      "169  0.01    0.000398          NaN         NaN  0.000124     34.80\n",
      "\n",
      "[170 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 1.790, Accuracy 34.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.91it/s]\n",
      "test_batch (Avg. Loss 1.865, Accuracy 34.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.03it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "166  0.01    0.000337          NaN         NaN  0.000124     31.48\n",
      "167  0.01    0.000357          NaN         NaN  0.000124     36.48\n",
      "168  0.01    0.000378          NaN         NaN  0.000124     33.44\n",
      "169  0.01    0.000398          NaN         NaN  0.000124     34.80\n",
      "170  0.01    0.000418          NaN         NaN  0.000124     34.88\n",
      "\n",
      "[171 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.302, Accuracy 14.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 2.198, Accuracy 19.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 21.75it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.141, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.37it/s]\n",
      "test_batch (Avg. Loss 2.088, Accuracy 21.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.25it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.038, Accuracy 24.6): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.11it/s]\n",
      "test_batch (Avg. Loss 2.036, Accuracy 24.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.54it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.981, Accuracy 25.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.25it/s]\n",
      "train_batch (Avg. Loss 2.029, Accuracy 24.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.38it/s]\n",
      "test_batch (Avg. Loss 2.071, Accuracy 24.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.42it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.002, Accuracy 25.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n",
      "test_batch (Avg. Loss 2.020, Accuracy 24.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.60it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "test_batch (Avg. Loss 2.214, Accuracy 20.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.44it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 2.195, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.61it/s]\n",
      "test_batch (Avg. Loss 2.193, Accuracy 20.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.60it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 2.166, Accuracy 20.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 2.152, Accuracy 21.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.35it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 2.128, Accuracy 21.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.88it/s]\n",
      "test_batch (Avg. Loss 2.123, Accuracy 21.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 22.68it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 2.111, Accuracy 20.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.24it/s]\n",
      "train_batch (Avg. Loss 1.961, Accuracy 28.0): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.13it/s]\n",
      "test_batch (Avg. Loss 1.996, Accuracy 27.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.89it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.944, Accuracy 29.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n",
      "test_batch (Avg. Loss 1.978, Accuracy 28.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.60it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "test_batch (Avg. Loss 1.910, Accuracy 31.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.29it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.884, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n",
      "test_batch (Avg. Loss 1.897, Accuracy 31.7): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.99it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "174  0.01    0.000500          NaN         NaN  0.000124     33.48\n",
      "175  0.01    0.000010          NaN         NaN  0.000143     23.56\n",
      "176  0.01    0.000030          NaN         NaN  0.000143     28.56\n",
      "177  0.01    0.000051          NaN         NaN  0.000143     30.72\n",
      "178  0.01    0.000071          NaN         NaN  0.000143     31.68\n",
      "\n",
      "[179 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.377, Accuracy 11.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.96it/s]\n",
      "test_batch (Avg. Loss 2.294, Accuracy 15.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.73it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.368, Accuracy 12.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.99it/s]\n",
      "test_batch (Avg. Loss 2.268, Accuracy 15.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.30it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.215, Accuracy 17.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.05it/s]\n",
      "test_batch (Avg. Loss 2.178, Accuracy 20.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.16it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.136, Accuracy 20.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.01it/s]\n",
      "train_batch (Avg. Loss 2.135, Accuracy 21.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.98it/s]\n",
      "test_batch (Avg. Loss 2.119, Accuracy 24.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.69it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.054, Accuracy 22.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.92it/s]\n",
      "test_batch (Avg. Loss 2.029, Accuracy 24.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.89it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.986, Accuracy 27.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.85it/s]\n",
      "train_batch (Avg. Loss 1.941, Accuracy 28.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.96it/s]\n",
      "test_batch (Avg. Loss 1.955, Accuracy 27.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.48it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.905, Accuracy 29.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 1.898, Accuracy 32.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.26it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.842, Accuracy 33.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.02it/s]\n",
      "test_batch (Avg. Loss 1.884, Accuracy 33.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.49it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.811, Accuracy 34.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n",
      "test_batch (Avg. Loss 1.861, Accuracy 33.5): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.85it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.775, Accuracy 36.0): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.16it/s]\n",
      "train_batch (Avg. Loss 1.767, Accuracy 35.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.89it/s]\n",
      "test_batch (Avg. Loss 1.858, Accuracy 34.5): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.62it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "180  0.01    0.000112          NaN         NaN  0.000143     33.88\n",
      "181  0.01    0.000132          NaN         NaN  0.000143     34.12\n",
      "182  0.01    0.000153          NaN         NaN  0.000143     35.28\n",
      "183  0.01    0.000173          NaN         NaN  0.000143     33.68\n",
      "184  0.01    0.000194          NaN         NaN  0.000143     34.92\n",
      "\n",
      "[185 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.333, Accuracy 13.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.01it/s]\n",
      "test_batch (Avg. Loss 2.227, Accuracy 17.8): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.90it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 1.959, Accuracy 27.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "test_batch (Avg. Loss 1.954, Accuracy 28.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.45it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.906, Accuracy 28.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.12it/s]\n",
      "test_batch (Avg. Loss 1.924, Accuracy 30.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.69it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.861, Accuracy 31.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n",
      "test_batch (Avg. Loss 1.910, Accuracy 31.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.58it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.822, Accuracy 33.7): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.22it/s]\n",
      "test_batch (Avg. Loss 1.870, Accuracy 33.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.48it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.797, Accuracy 33.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.53it/s]\n",
      "test_batch (Avg. Loss 1.836, Accuracy 33.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.53it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "181  0.01    0.000132          NaN         NaN  0.000143     34.12\n",
      "182  0.01    0.000153          NaN         NaN  0.000143     35.28\n",
      "183  0.01    0.000173          NaN         NaN  0.000143     33.68\n",
      "184  0.01    0.000194          NaN         NaN  0.000143     34.92\n",
      "185  0.01    0.000214          NaN         NaN  0.000143     33.24\n",
      "\n",
      "[186 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 1.760, Accuracy 35.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n",
      "test_batch (Avg. Loss 1.810, Accuracy 35.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.27it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "184  0.01    0.000194          NaN         NaN  0.000143     34.92\n",
      "185  0.01    0.000214          NaN         NaN  0.000143     33.24\n",
      "186  0.01    0.000235          NaN         NaN  0.000143     33.24\n",
      "187  0.01    0.000255          NaN         NaN  0.000143     34.68\n",
      "188  0.01    0.000275          NaN         NaN  0.000143     35.88\n",
      "\n",
      "[189 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.318, Accuracy 14.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.05it/s]\n",
      "test_batch (Avg. Loss 2.208, Accuracy 19.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.90it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "test_batch (Avg. Loss 2.088, Accuracy 25.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.10it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.019, Accuracy 25.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.04it/s]\n",
      "test_batch (Avg. Loss 2.058, Accuracy 23.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.30it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.954, Accuracy 28.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.87it/s]\n",
      "test_batch (Avg. Loss 2.001, Accuracy 29.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.43it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "test_batch (Avg. Loss 2.012, Accuracy 24.9): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.72it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.913, Accuracy 29.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 1.940, Accuracy 31.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.24it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.853, Accuracy 32.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.94it/s]\n",
      "test_batch (Avg. Loss 1.904, Accuracy 31.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.58it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.809, Accuracy 34.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.99it/s]\n",
      "test_batch (Avg. Loss 1.880, Accuracy 32.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.52it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.796, Accuracy 34.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.10it/s]\n",
      "train_batch (Avg. Loss 1.865, Accuracy 32.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.26it/s]\n",
      "test_batch (Avg. Loss 1.862, Accuracy 34.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.04it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.822, Accuracy 33.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.93it/s]\n",
      "test_batch (Avg. Loss 1.867, Accuracy 33.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.27it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.795, Accuracy 35.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.50it/s]\n",
      "test_batch (Avg. Loss 1.953, Accuracy 29.5): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.82it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.868, Accuracy 32.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.22it/s]\n",
      "test_batch (Avg. Loss 1.927, Accuracy 30.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.33it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.822, Accuracy 33.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.32it/s]\n",
      "test_batch (Avg. Loss 1.894, Accuracy 32.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.46it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.796, Accuracy 34.9): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.26it/s]\n",
      "test_batch (Avg. Loss 1.867, Accuracy 34.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.96it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.756, Accuracy 36.3): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.20it/s]\n",
      "test_batch (Avg. Loss 1.843, Accuracy 35.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.19it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "190  0.01    0.000316          NaN         NaN  0.000143     34.60\n",
      "191  0.01    0.000337          NaN         NaN  0.000143     35.72\n",
      "192  0.01    0.000357          NaN         NaN  0.000143     36.20\n",
      "193  0.01    0.000378          NaN         NaN  0.000143     34.24\n",
      "194  0.01    0.000398          NaN         NaN  0.000143     35.40\n",
      "\n",
      "[195 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.304, Accuracy 14.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.71it/s]\n",
      "train_batch (Avg. Loss 1.856, Accuracy 32.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.73it/s]\n",
      "test_batch (Avg. Loss 1.872, Accuracy 32.1): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.85it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.808, Accuracy 34.7): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.29it/s]\n",
      "test_batch (Avg. Loss 1.843, Accuracy 34.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.68it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "193  0.01    0.000378          NaN         NaN  0.000143     34.24\n",
      "194  0.01    0.000398          NaN         NaN  0.000143     35.40\n",
      "195  0.01    0.000418          NaN         NaN  0.000143     34.44\n",
      "196  0.01    0.000439          NaN         NaN  0.000143     36.36\n",
      "197  0.01    0.000459          NaN         NaN  0.000143     34.56\n",
      "\n",
      "[198 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.145, Accuracy 19.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.87it/s]\n",
      "test_batch (Avg. Loss 2.076, Accuracy 22.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.46it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.034, Accuracy 23.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.89it/s]\n",
      "test_batch (Avg. Loss 2.083, Accuracy 23.0): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 22.33it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.998, Accuracy 24.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.20it/s]\n",
      "test_batch (Avg. Loss 1.979, Accuracy 24.9): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.79it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.926, Accuracy 28.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n",
      "test_batch (Avg. Loss 1.984, Accuracy 28.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.31it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.885, Accuracy 31.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.96it/s]\n",
      "train_batch (Avg. Loss 2.195, Accuracy 18.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.98it/s]\n",
      "test_batch (Avg. Loss 2.193, Accuracy 19.9): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.71it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 2.166, Accuracy 20.6): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.22it/s]\n",
      "test_batch (Avg. Loss 2.153, Accuracy 21.3): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.04it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 2.128, Accuracy 21.2): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.15it/s]\n",
      "test_batch (Avg. Loss 2.123, Accuracy 22.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.44it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 2.111, Accuracy 21.0): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.24it/s]\n",
      "test_batch (Avg. Loss 2.116, Accuracy 20.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.37it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 2.092, Accuracy 22.3): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.21it/s]\n",
      "test_batch (Avg. Loss 2.089, Accuracy 23.7): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.99it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "196  0.01    0.000439          NaN         NaN  0.000143     36.36\n",
      "197  0.01    0.000459          NaN         NaN  0.000143     34.56\n",
      "198  0.01    0.000480          NaN         NaN  0.000143     34.40\n",
      "199  0.01    0.000500          NaN         NaN  0.000143     34.08\n",
      "200  0.01    0.000010          NaN         NaN  0.000162     23.68\n",
      "\n",
      "[201 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 1.963, Accuracy 27.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.07it/s]\n",
      "test_batch (Avg. Loss 1.987, Accuracy 26.6): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.22it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.917, Accuracy 29.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.11it/s]\n",
      "test_batch (Avg. Loss 1.947, Accuracy 30.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.22it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.888, Accuracy 31.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.85it/s]\n",
      "train_batch (Avg. Loss 1.823, Accuracy 34.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.73it/s]\n",
      "test_batch (Avg. Loss 1.881, Accuracy 33.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.08it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "201  0.01    0.000030          NaN         NaN  0.000162     28.52\n",
      "202  0.01    0.000051          NaN         NaN  0.000162     30.36\n",
      "203  0.01    0.000071          NaN         NaN  0.000162     30.96\n",
      "204  0.01    0.000092          NaN         NaN  0.000162     31.80\n",
      "205  0.01    0.000112          NaN         NaN  0.000162     33.44\n",
      "\n",
      "[206 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.358, Accuracy 12.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.83it/s]\n",
      "test_batch (Avg. Loss 2.251, Accuracy 16.0): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.63it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.119, Accuracy 20.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.04it/s]\n",
      "test_batch (Avg. Loss 2.064, Accuracy 23.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.20it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 2.047, Accuracy 23.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.98it/s]\n",
      "test_batch (Avg. Loss 2.062, Accuracy 24.3): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.58it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "test_batch (Avg. Loss 1.915, Accuracy 30.6): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.69it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.875, Accuracy 31.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.04it/s]\n",
      "test_batch (Avg. Loss 1.912, Accuracy 31.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.49it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.856, Accuracy 32.1): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.04it/s]\n",
      "test_batch (Avg. Loss 1.881, Accuracy 32.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.93it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.821, Accuracy 33.7): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.13it/s]\n",
      "test_batch (Avg. Loss 1.877, Accuracy 32.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.26it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.791, Accuracy 35.2): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.07it/s]\n",
      "train_batch (Avg. Loss 2.176, Accuracy 19.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.96it/s]\n",
      "test_batch (Avg. Loss 2.147, Accuracy 19.4): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.29it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.088, Accuracy 21.8): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.51it/s]\n",
      "test_batch (Avg. Loss 2.048, Accuracy 22.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.01it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.985, Accuracy 25.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.59it/s]\n",
      "test_batch (Avg. Loss 2.024, Accuracy 23.9): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.63it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.960, Accuracy 27.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.01it/s]\n",
      "test_batch (Avg. Loss 1.993, Accuracy 26.7): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.35it/s]\n",
      "--- EPOCH 6/10 ---\n",
      "train_batch (Avg. Loss 1.917, Accuracy 28.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.94it/s]\n",
      "test_batch (Avg. Loss 1.953, Accuracy 30.0): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.40it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.890, Accuracy 30.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.03it/s]\n",
      "test_batch (Avg. Loss 1.943, Accuracy 28.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.35it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "test_batch (Avg. Loss 1.849, Accuracy 33.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.44it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.764, Accuracy 36.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.00it/s]\n",
      "test_batch (Avg. Loss 1.829, Accuracy 35.3): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.26it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "210  0.01    0.000214          NaN         NaN  0.000162     33.00\n",
      "211  0.01    0.000235          NaN         NaN  0.000162     33.72\n",
      "212  0.01    0.000255          NaN         NaN  0.000162     34.28\n",
      "213  0.01    0.000275          NaN         NaN  0.000162     34.16\n",
      "214  0.01    0.000296          NaN         NaN  0.000162     35.28\n",
      "\n",
      "[215 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "train_batch (Avg. Loss 2.316, Accuracy 14.0): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.91it/s]\n",
      "test_batch (Avg. Loss 2.204, Accuracy 19.8): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.54it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 1.897, Accuracy 31.5): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.95it/s]\n",
      "test_batch (Avg. Loss 1.900, Accuracy 33.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.25it/s]\n",
      "--- EPOCH 7/10 ---\n",
      "train_batch (Avg. Loss 1.830, Accuracy 32.5): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.10it/s]\n",
      "test_batch (Avg. Loss 1.871, Accuracy 33.1): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.36it/s]\n",
      "--- EPOCH 8/10 ---\n",
      "train_batch (Avg. Loss 1.793, Accuracy 34.4): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.20it/s]\n",
      "test_batch (Avg. Loss 1.858, Accuracy 33.4): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.14it/s]\n",
      "--- EPOCH 9/10 ---\n",
      "train_batch (Avg. Loss 1.757, Accuracy 35.4): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.08it/s]\n",
      "test_batch (Avg. Loss 1.845, Accuracy 35.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.63it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.771, Accuracy 35.9): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.64it/s]\n",
      "test_batch (Avg. Loss 1.819, Accuracy 36.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.02it/s]\n",
      "--- EPOCH 10/10 ---\n",
      "train_batch (Avg. Loss 1.747, Accuracy 36.7): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.95it/s]\n",
      "test_batch (Avg. Loss 1.786, Accuracy 36.5): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.53it/s]\n",
      "     wstd  lr_vanilla  lr_momentum  lr_rmsprop       reg  accuracy\n",
      "0    0.01    0.000010          NaN         NaN  0.000010     23.36\n",
      "1    0.01    0.000030          NaN         NaN  0.000010     28.56\n",
      "2    0.01    0.000051          NaN         NaN  0.000010     31.24\n",
      "3    0.01    0.000071          NaN         NaN  0.000010     31.00\n",
      "4    0.01    0.000092          NaN         NaN  0.000010     34.92\n",
      "..    ...         ...          ...         ...       ...       ...\n",
      "214  0.01    0.000296          NaN         NaN  0.000162     35.28\n",
      "215  0.01    0.000316          NaN         NaN  0.000162     35.64\n",
      "216  0.01    0.000337          NaN         NaN  0.000162     33.92\n",
      "217  0.01    0.000357          NaN         NaN  0.000162     34.68\n",
      "218  0.01    0.000378          NaN         NaN  0.000162     36.52\n",
      "\n",
      "[219 rows x 6 columns]\n",
      "--- EPOCH 1/10 ---\n",
      "test_batch (Avg. Loss 2.112, Accuracy 21.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.96it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "train_batch (Avg. Loss 2.043, Accuracy 24.0): 100%|██████████████████████████████████| 100/100 [00:10<00:00,  9.16it/s]\n",
      "test_batch (Avg. Loss 2.099, Accuracy 21.3): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 23.38it/s]\n",
      "--- EPOCH 4/10 ---\n",
      "train_batch (Avg. Loss 1.991, Accuracy 25.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.92it/s]\n",
      "train_batch (Avg. Loss 2.302, Accuracy 14.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.40it/s]\n",
      "test_batch (Avg. Loss 2.198, Accuracy 19.2): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 25.95it/s]\n",
      "--- EPOCH 2/10 ---\n",
      "train_batch (Avg. Loss 2.141, Accuracy 18.6): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  9.07it/s]\n",
      "test_batch (Avg. Loss 2.093, Accuracy 20.9): 100%|███████████████████████████████████| 100/100 [00:03<00:00, 26.12it/s]\n",
      "--- EPOCH 3/10 ---\n",
      "test_batch (Avg. Loss 1.986, Accuracy 25.2): 100%|███████████████████████████████████| 100/100 [00:04<00:00, 24.66it/s]\n",
      "--- EPOCH 5/10 ---\n",
      "train_batch (Avg. Loss 1.938, Accuracy 27.3): 100%|██████████████████████████████████| 100/100 [00:11<00:00,  8.53it/s]\n",
      "test_batch (2.125):  47%|████████████████████████████▋                                | 47/100 [00:01<00:02, 25.11it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "##======================todo:yaniv:delete!=============================================    \n",
    "##======================todo:yaniv:delete!=============================================    \n",
    "##======================todo:yaniv:delete!=============================================    \n",
    "\n",
    "# Define a larger part of the CIFAR-10 dataset (still not the whole thing)\n",
    "batch_size = 50\n",
    "max_batches = 100\n",
    "in_features = 3 * 32 * 32\n",
    "num_classes = 10\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=False)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size // 2, shuffle=False)\n",
    "\n",
    "# Define a function to train a model with our Trainer and various optimizers\n",
    "def train_with_optimizer(opt_name, opt_class, hp):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Get hyperparameters\n",
    "    hidden_features = [128] * 5\n",
    "    num_epochs = 10\n",
    "\n",
    "    # Create model, loss and optimizer instances\n",
    "    model = layers.MLP(in_features, num_classes, hidden_features, wstd=hp['wstd'])\n",
    "    loss_fn = layers.CrossEntropyLoss()\n",
    "    optimizer = opt_class(model.params(), learn_rate=hp[f'lr_{opt_name}'], reg=hp['reg'])\n",
    "\n",
    "    # Train with the Trainer\n",
    "    trainer = training.LayerTrainer(model, loss_fn, optimizer)\n",
    "    fit_res = trainer.fit(dl_train, dl_test, num_epochs, max_batches=max_batches)\n",
    "\n",
    "    return fit_res\n",
    "\n",
    "\n",
    "\n",
    "best_results = pd.DataFrame(columns=['wstd', 'lr_vanilla', 'lr_momentum', 'lr_rmsprop', 'reg', 'accuracy'])\n",
    "\n",
    "for wstd in [0.01, 0.05, 0.1]:\n",
    "    for reg in np.linspace(1e-5, 0.0002, 11):\n",
    "        for lr_vanilla in np.linspace(1e-5, 0.0005, 25):\n",
    "            hp = dict(wstd=wstd, lr_vanilla=lr_vanilla, lr_momentum=None, lr_rmsprop=None, reg=reg)\n",
    "            res = train_with_optimizer('vanilla', optimizers.VanillaSGD, hp)\n",
    "            best_results = best_results.append(\n",
    "                {'wstd': hp['wstd'], 'lr_vanilla': hp['lr_vanilla'], 'lr_momentum': hp['lr_momentum'],\n",
    "                 'lr_rmsprop': hp['lr_rmsprop'], 'reg': hp['reg'], 'accuracy': max(res.test_acc)},\n",
    "                ignore_index=True)\n",
    "            print(best_results)\n",
    "            with open('.\\search_outputs.pickle', mode='wb') as handle:\n",
    "                pickle.dump(best_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print('********************************************Summary*************************************')\n",
    "print(best_results)\n",
    "print('****************************************************************************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "1. Complete the implementation of the `test_batch()` method in the `LayerTrainer` class within the `hw2/training.py` module.\n",
    "1. Implement the `fit()` method of the `Trainer` class within the `hw2/training.py` module.\n",
    "1. Tweak the hyperparameters for this section in the `part2_optim_hp()` function in the `hw2/answers.py` module.\n",
    "1. Run the following code blocks to train. Try to get above 35-40% test-set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a larger part of the CIFAR-10 dataset (still not the whole thing)\n",
    "batch_size = 50\n",
    "max_batches = 100\n",
    "in_features = 3*32*32\n",
    "num_classes = 10\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=False)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size//2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train a model with our Trainer and various optimizers\n",
    "def train_with_optimizer(opt_name, opt_class, fig):\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Get hyperparameters\n",
    "    hp = answers.part2_optim_hp()\n",
    "    hidden_features = [128] * 5\n",
    "    num_epochs = 10\n",
    "    \n",
    "    # Create model, loss and optimizer instances\n",
    "    model = layers.MLP(in_features, num_classes, hidden_features, wstd=hp['wstd'])\n",
    "    loss_fn = layers.CrossEntropyLoss()\n",
    "    optimizer = opt_class(model.params(), learn_rate=hp[f'lr_{opt_name}'], reg=hp['reg'])\n",
    "\n",
    "    # Train with the Trainer\n",
    "    trainer = training.LayerTrainer(model, loss_fn, optimizer)\n",
    "    fit_res = trainer.fit(dl_train, dl_test, num_epochs, max_batches=max_batches)\n",
    "    \n",
    "    fig, axes = plot_fit(fit_res, fig=fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_optim = None\n",
    "fig_optim = train_with_optimizer('vanilla', optimizers.VanillaSGD, fig_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "<a id=part2_4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple vanilla SGD update is rarely used in practice since it's very slow to converge relative to other optimization algorithms.\n",
    "\n",
    "One reason is that naïvely updating in the direction of the current gradient causes it to fluctuate wildly in areas where the loss surface in some dimensions is much steeper than in others.\n",
    "Another reason is that using the same learning rate for all parameters is not a great idea since not all parameters are created equal. For example, parameters associated with rare features should be updated with a larger step than ones associated with commonly-occurring features because they'll get less updates through the gradients.\n",
    "\n",
    "Therefore more advanced optimizers take into account the previous gradients of a parameter and/or try to use a per-parameter specific learning rate instead of a common one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now implement a simple and common optimizer: SGD with Momentum. This optimizer takes **previous gradients** of a parameter into account when updating it's value instead of just the current one. In practice it usually provides faster convergence than the vanilla SGD.\n",
    "\n",
    "The SGD with Momentum update rule can be stated as follows:\n",
    "$$\\begin{align}\n",
    "\\vec{v}_{t+1} &= \\mu \\vec{v}_t - \\eta \\delta \\vec{\\theta}_t \\\\\n",
    "\\vec{\\theta}_{t+1} &= \\vec{\\theta}_t + \\vec{v}_{t+1}\n",
    "\\end{align}$$\n",
    "\n",
    "Where $\\eta$ is the learning rate,\n",
    "$\\vec{\\theta}$ is a model parameter,\n",
    "$\\delta \\vec{\\theta}_t=\\pderiv{L}{\\vec{\\theta}}(\\vec{\\theta}_t)$ is the gradient of the loss w.r.t. to the parameter and $0\\leq\\mu<1$ is a hyperparameter known as momentum. \n",
    "\n",
    "Expanding the update rule recursively shows us now the parameter update infact depends on all previous gradient values for that parameter, where the old gradients are exponentially decayed by a factor of $\\mu$ at each timestep. \n",
    "\n",
    "Since we're incorporating previous gradient (update directions), a noisy value of the current gradient will have less effect so that the general direction of previous updates is maintained somewhat. The following figure illustrates this.\n",
    "\n",
    "<img src=\"imgs/sgd-momentum.png\" width=\"600\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "1. Complete the implementation of the `MomentumSGD` class in the `hw2/optimizers.py` module.\n",
    "1. Tweak the learning rate for momentum in `part2_optim_hp()` the function in the `hw2/answers.py` module.\n",
    "1. Run the following code block to compare to the vanilla SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_optim = train_with_optimizer('momentum', optimizers.MomentumSGD, fig_optim)\n",
    "fig_optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp - Bonus\n",
    "<a id=part2_5></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another optmizer that accounts for previous gradients, but this time it uses them to adapt the learning rate per parameter.\n",
    "\n",
    "RMSProp maintains a decaying moving average of previous squared gradients,\n",
    "$$\n",
    "\\vec{r}_{t+1} = \\gamma\\vec{r}_{t} + (1-\\gamma)\\delta\\vec{\\theta}_t^2\n",
    "$$\n",
    "where $0<\\gamma<1$ is a decay constant usually set close to $1$, and $\\delta\\vec{\\theta}_t^2$ denotes\n",
    "element-wise squaring.\n",
    "\n",
    "The update rule for each parameter is then,\n",
    "$$\n",
    "\\vec{\\theta}_{t+1} = \\vec{\\theta}_t - \\left( \\frac{\\eta}{\\sqrt{r_{t+1}+\\varepsilon}} \\right) \\delta\\vec{\\theta}_t\n",
    "$$\n",
    "\n",
    "where $\\varepsilon$ is a small constant to prevent numerical instability. The idea here is to decrease the learning rate for parameters with high gradient values and vice-versa. The decaying moving average prevents accumulating all the past gradients which would cause the effective learning rate to become zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "1. Complete the implementation of the `RMSProp` class in the `hw2/optimizers.py` module.\n",
    "1. Tweak the learning rate for RMSProp in `part2_optim_hp()` the function in the `hw2/answers.py` module.\n",
    "1. Run the following code block to compare to the other optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_optim = train_with_optimizer('rmsprop', optimizers.RMSProp, fig_optim)\n",
    "fig_optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you should get better train/test accuracy with Momentum and RMSProp than Vanilla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Regularization - Bonus\n",
    "<a id=part2_6></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dropout](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf) is a useful technique to improve generalization of deep models.\n",
    "\n",
    "The idea is simple: during the forward pass drop, i.e. set to to zero, the activation of each neuron, with a probability of $p$. For example, if $p=0.4$ this means we **drop** the activations of 40% of the neurons (on average).\n",
    "\n",
    "There are a few important things to note about dropout:\n",
    "1. It is only performed during training. When testing our model the dropout layers should be a no-op.\n",
    "1. In the backward pass, gradients are only propagated back into neurons that weren't dropped during the forward pass.\n",
    "1. During testing, the activations must be scaled since the expected value of each neuron during the training phase is now $1-p$ times it's original expectation. Thus, we need to scale the test-time activations by $1-p$ to match. Equivalently, we can scale the train time activations by $1/(1-p)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "1. Complete the implementation of the `Dropout` class in the `hw2/layers.py` module.\n",
    "2. Finish the implementation of the `MLP`'s `__init__()` method in the `hw2/layers.py` module.\n",
    "   If `dropout>0` you should add a `Dropout` layer after each `ReLU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2.grad_compare import compare_layer_to_torch\n",
    "\n",
    "# Check architecture of MLP with dropout layers\n",
    "mlp_dropout = layers.MLP(in_features, num_classes, [50]*3, dropout=0.6)\n",
    "print(mlp_dropout)\n",
    "test.assertEqual(len(mlp_dropout.sequence), 10)\n",
    "for b1, b2 in zip(mlp_dropout.sequence, mlp_dropout.sequence[1:]):\n",
    "    if str(b1).lower() == 'relu':\n",
    "        test.assertTrue(str(b2).startswith('Dropout'))\n",
    "test.assertTrue(str(mlp_dropout.sequence[-1]).startswith('Linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test end-to-end gradient in train and test modes.\n",
    "print('Dropout, train mode')\n",
    "mlp_dropout.train(True)\n",
    "for diff in compare_layer_to_torch(mlp_dropout, torch.randn(500, in_features)):\n",
    "    test.assertLess(diff, 1e-3)\n",
    "    \n",
    "print('Dropout, test mode')\n",
    "mlp_dropout.train(False)\n",
    "for diff in compare_layer_to_torch(mlp_dropout, torch.randn(500, in_features)):\n",
    "    test.assertLess(diff, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether dropout really improves generalization, let's take a small training set\n",
    "(small enough to overfit) and a large test set and check whether we get less overfitting and\n",
    "perhaps improved test-set accuracy when using dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small set from CIFAR-10, but take a larger test set since we want to test generalization\n",
    "batch_size = 10\n",
    "max_batches = 40\n",
    "in_features = 3*32*32\n",
    "num_classes = 10\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=False)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provided**:\n",
    "\n",
    "Tweak the hyperparameters for this section in the `part2_dropout_hp()` function in the `hw2/answers.py` module. Try to set them so that the first model (with `dropout`=0) overfits. You can disable the other dropout options until you tune the hyperparameters. We can then see the effect of dropout for generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hyperparameters\n",
    "hp = answers.part2_dropout_hp()\n",
    "hidden_features = [400] * 1\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "fig=None\n",
    "#for dropout in [0]:  # Use this for tuning the hyperparms until you overfit\n",
    "for dropout in [0, 0.4, 0.8]:\n",
    "    model = layers.MLP(in_features, num_classes, hidden_features, wstd=hp['wstd'], dropout=dropout)\n",
    "    loss_fn = layers.CrossEntropyLoss()\n",
    "    optimizer = optimizers.MomentumSGD(model.params(), learn_rate=hp['lr'], reg=0)\n",
    "\n",
    "    print('*** Training with dropout=', dropout)\n",
    "    trainer = training.LayerTrainer(model, loss_fn, optimizer)\n",
    "    fit_res_dropout = trainer.fit(dl_train, dl_test, num_epochs, max_batches=max_batches, print_every=6)\n",
    "    fig, axes = plot_fit(fit_res_dropout, fig=fig, legend=f'dropout={dropout}', log_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "<a id=part2_7></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Answer the following questions. Write your answers in the appropriate variables in the module `hw2/answers.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs3600.answers import display_answer\n",
    "import hw2.answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "Regarding the graphs you got for the three dropout configurations:\n",
    "\n",
    "1. Explain the graphs of no-dropout vs dropout. Do they match what you expected to see?\n",
    "    - If yes, explain why and provide examples based on the graphs.\n",
    "    - If no, explain what you think the problem is and what should be modified to fix it.\n",
    "\n",
    "2. Compare the low-dropout setting to the high-dropout setting and explain based on your graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_answer(hw2.answers.part2_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 \n",
    "\n",
    "When training a model with the cross-entropy loss function, is it possible for the test loss to **increase** for a few epochs while the test accuracy also **increases**?\n",
    "\n",
    "If it's possible explain how, if it's not explain why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_answer(hw2.answers.part2_q2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
