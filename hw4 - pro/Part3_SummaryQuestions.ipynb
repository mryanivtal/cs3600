{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\cset}[1]{\\mathcal{#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\given}[]{\\,\\middle\\vert\\,}\n",
    "\\newcommand{\\DKL}[2]{\\cset{D}_{\\text{KL}}\\left(#1\\,\\Vert\\, #2\\right)}\n",
    "\\newcommand{\\grad}[]{\\nabla}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "$$\n",
    "\n",
    "# Part 3: Summary Questions\n",
    "<a id=part2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains summary questions about various topics from the course material.\n",
    "\n",
    "You can add your answers in new cells below the questions.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "- Clearly mark where your answer begins, e.g. write \"**Answer:**\" in the beginning of your cell.\n",
    "- Provide a full explanation, even if the question doesn't explicitly state so. We will reduce points for partial explanations!\n",
    "- This notebook should be runnable from start to end without any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain the meaning of the term \"receptive field\" in the context of CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "A receptive field is the area in the input space that a point in the target space \"Sees\", or taking into account in the kernel calculation.\n",
    "It is defined by a center and a size. Naturally, a point in the target space cannot take into account data that is not in its receptive field. <Br>\n",
    "A receptive field of a single conv. layer is calculated as: <Br>\n",
    "$r_{i-1} = s_i \\cdot r_i + (k_i - s_i)$,<Br>\n",
    "Where: <Br>\n",
    "$r_{i-1}$ - receptive field of layer i-1 <Br>\n",
    "$s_i$ - Stride at layer i <Br>\n",
    "$k_i$ - kernel size at layer i-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explain and elaborate about three different ways to control the rate at which the receptive field grows from layer to layer. Compare them to each other in terms of how they combine input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Three ways to increase the receptive field:<Br>\n",
    "1. **Add conv. layers - make network deeper** - by adding more layers with kernel > 1, each point in the target space sees more ponits in the origin space.\n",
    "    This option increases the receptive field linearly - each additional layer increases the receptive field size by the kernel size.\n",
    "    This also typically adds a nonlinear layer (RELU etc.) per layer, making the network more complex.\n",
    "2. **Add pooling layers with corresponding stride** - RF grows with no. of pooling layers multiplicatively, becasue each pooling layer multiplies the RC by the pooling size. Note that without the stride, pooling layers will not multiply the RF, because neighbouring points will have almost the exact same RF, so pooling them together will not chnage much.   e.g. - adding a pooling layer with kernel 2 and strde 1 will change the RF from x to x+1 in each dimension, because the rest of the points in the origin space will be be the same.\n",
    "3. **Dilated convolution** - introduce spaces between kernel values, hence while the number of kernel weights is the same, the area covered is multiplied by r (dilation rate). <Br>\n",
    "    Hence, the RF grows exponentioally with \n",
    "    With that said, not all points in the original space are covered by each kernel, it is a sparse sampling of the space per kernel operation.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Imagine a CNN with three convolutional layers, defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 122, 122])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "cnn = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=4, out_channels=16, kernel_size=5, stride=2, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=7, dilation=2, padding=3),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "cnn(torch.rand(size=(1, 3, 1024, 1024), dtype=torch.float32)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the size (spatial extent) of the receptive field of each \"pixel\" in the output tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The receptive field after the last layer is 112x112. <Br>\n",
    "Explanation: for every layer, the output RC is provided by: $r = \\sum_{i=1}^{L} (d_i (k_i - 1) \\cdot \\Pi_{j=0}^{j-1} s_j ) +1$ <Br>\n",
    "    \n",
    "Please see the changes per layer in the following table, RELU layers ommitted because they have no impact on RC.<Br>\n",
    "first layer is calculated explicitly in the table as an example\n",
    "    \n",
    "\n",
    "    \n",
    "| Layer | k | s | d | RF Before | RF After | comments |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| Conv2d | 3 | 1 | 1 | 1 | 3 | $r = 1 \\cdot (3-1) \\cdot 1) + 1$ = 3 |\n",
    "| MaxPool2d | 2 | 2 | 1 | 3 | 4 | +1 overall, because the stride in the last conv. layer is 1 |\n",
    "| Conv2d | 5 | 2 | 1 | 4 | 12 | by the equation above |\n",
    "| MaxPool2d | 2 | 2 | 1 | 12 | 16 | by the equation above |\n",
    "| Conv2d | 7 | 1 | 2 | 16 | 112 | by the equation above |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. You have trained a CNN, where each layer $l$ is represented by the mapping $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)$, and $f_l(\\cdot;\\vec{\\theta}_l)$ is a convolutional layer (not including the activation function).\n",
    "\n",
    "  After hearing that residual networks can be made much deeper, you decide to change each layer in your network you used the following residual mapping instead $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)+\\vec{x}$, and re-train.\n",
    "\n",
    "  However, to your surprise, by visualizing the learned filters $\\vec{\\theta}_l$ you observe that the original network and the residual network produce completely different filters. Explain the reason for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** <Br>\n",
    "This makes sense because the filters are learned parameters and the learned distribution is different.<Br>\n",
    "In \"Regular\" CNN the conv. layer tries to learn the original target distribution $H(x)$, hence $x \\rightarrow H(x)$. <Br>\n",
    "In Resnet, since we add $x \\cdot I$ to the output, the conv. layer tries to learn $x \\rightarrow H(x) - x$. <Br>\n",
    "This is also where the name comes from:  $Residual = R(x) := H(x)-x$<Br>\n",
    "Since the learned distribution is totally different, the filters (learned params) are also different.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Consider the following neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T09:18:17.992615Z",
     "iopub.status.busy": "2021-01-26T09:18:17.991868Z",
     "iopub.status.idle": "2021-01-26T09:18:18.013482Z",
     "shell.execute_reply": "2021-01-26T09:18:18.014164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.1, inplace=False)\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "p1, p2 = 0.1, 0.2\n",
    "nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p1),\n",
    "    nn.Dropout(p=p2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to replace the two consecutive dropout layers with a single one defined as follows:\n",
    "```python\n",
    "nn.Dropout(p=q)\n",
    "```\n",
    "what would the value of `q` need to be? Write an expression for `q` in terms of `p1` and `p2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** <Br>\n",
    "$q = p_1 + p_2 - p_1 \\cdot p_2 = 0.28$ <Br>\n",
    "Explanation: <Br>\n",
    "Each connection can be dropped (Zeroed) :<Br>\n",
    "- Exclusively by the first dropout with probability $p1 - p_1 \\cdot p_2$\n",
    "- Exclusively by the second dropout with probability $p2 - p_1 \\cdot p_2$\n",
    "- By both (same result as being dropped once) with probability $p_1 \\cdot p_2$<Br>\n",
    "<Br>\n",
    "So, to cancel duplication, we need to sum the three and get the union probability: $q = p_1 + p_2 - p_1 \\cdot p_2 = 0.28$ <Br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **True or false**: dropout must be placed only after the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "False - It is the general practice to place the dropout layer after the activation layer, and based on the selection activation function this could lead to different results (e.g. - with Sigmoid). <Br>\n",
    "With RELU the results are identical regardless of the order of these layers (RELU of 0 is 0) so it could be more computationally efficient to place the dropouts before the RELU.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. After applying dropout with a drop-probability of $p$, the activations are scaled by $1/(1-p)$. Prove that this scaling is required in order to maintain the value of each activation unchanged in expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**<Br>\n",
    "Let $\\vec{x}$ be the tensor of values after the activation function, and <Br>\n",
    "Let the expected value of $x_i$ be equal to some value $a$, so $\\forall i: E(x_i) = a$ <Br>\n",
    "so if we dropout (Zero) elements in $\\vec x$ with probability $p$, so the new expectation is:<Br>\n",
    "$\\forall i: E(x_i) = (1-p)a$ <Br>\n",
    "In order to set it back to $a$, we multiply by $\\dfrac{1}{1-p}$, so that:<br>\n",
    "$E(x_i) = (1-p) \\cdot \\dfrac{1}{1-p} \\cdot a = a$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You're training a an image classifier that, given an image, needs to classify it as either a dog (output 0) or a hotdog (output 1). Would you train this model with an L2 loss? if so, why? if not, demonstrate with a numerical example. What would you use instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** For a binary classifier I would not use an L2 loss because it is more suitable for values in the range $[-\\infty, \\infty]$, while the error values of classifiers are in the probability range, i.e. $[0, 1]$.\n",
    "Instead I would use binary cross-entropy loss, which is designed for probabilities in the range of $[0, 1]$.<Br>\n",
    "\n",
    "Generally speaking, we want loss funcitons to \"Punish\" big mistakes strongly and small mistakes weakly, with significantly different gradient values between these cases.    As can be seen in the plot below, in the relevant error range of $[0, 1]$:\n",
    "- L2 loss behaves almost linearly, with loss values in $[0, 1]$ - small loss range, no \"growing punsihment\" for large error (almost const. gradient)\n",
    "- Binary Cross-entropy (log loss) behaves much more as described above - loss range $[0, \\infty]$, gradient growing with the loss \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14a3c35fc40>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 1-1e-3, 100)\n",
    "se = (0-x)**2\n",
    "bce = -np.log(1-x)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(x, se, color='r', label='L2')\n",
    "plt.plot(x, bce, color='b', label='BCE')\n",
    "plt.xlabel('Error= y - y_pred')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. After months of research into the origins of climate change, you observe the following result:\n",
    "\n",
    "<center><img src=\"https://sparrowism.soc.srcf.net/home/piratesarecool4.gif\" /></center>\n",
    "\n",
    "You decide to train a cutting-edge deep neural network regression model, that will predict the global temperature based on the population of pirates in `N` locations around the globe.\n",
    "You define your model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N = 42  # number of known global pirate hot spots\n",
    "H = 128\n",
    "mlpirate = nn.Sequential(\n",
    "    nn.Linear(in_features=N, out_features=H),\n",
    "    nn.Sigmoid(),\n",
    "    *[\n",
    "        nn.Linear(in_features=H, out_features=H), nn.Sigmoid(),\n",
    "    ]*24,\n",
    "    nn.Linear(in_features=H, out_features=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training your model you notice that the loss reaches a plateau after only a few iterations.\n",
    "It seems that your model is no longer training.\n",
    "What is the most likely cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The most likely cause is vanishing gradients.\n",
    "Sigmoid function takes very wide range of input and squashes it to a very small output rane of $[0,1]$, hence for values far from zero the gradient is very close to zero.   \n",
    "In a deep network, with many such layers stacked, the training tends to get stuck in a stable state where the parameter values are extreme (Far from zero), the gradient is numerically zero, and so the optimizer gets stuck in place and the loss does not improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Referring to question 2 above: A friend suggests that if you replace the `sigmoid` activations with `tanh`, it will solve your problem. Is he correct? Explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "No it will not solve the problem.    \n",
    "Tanh function is veri similar to sigmoid in the attributes mentioned above, only the target range is $[-1, 1]$ instead of $[0, 1]$.  \n",
    "The same problem will occure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Regarding the ReLU activation, state whether the following sentences are **true or false** and explain:<br>\n",
    " A. In a model using exclusively ReLU activations, there can be no vanishing gradients.<br>\n",
    " B. The gradient of ReLU is linear with its input when the input is positive.<br>\n",
    " C. ReLU can cause \"dead\" neurons, i.e. activations that remain at a constant value of zero.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:** <Br>\n",
    "A. **False** - Relu can cause vanishing gradients as well in case of negative values, because when $x \\leq 0$ the gradient is 0<br>\n",
    "B. **False** - The gradient of RELU is constant for any x>0 - and equals to the relu slope<br>\n",
    "C. **True** - for $x \\leq 0$ the ReLU returns zero.   If the weights are such that any actual input that reach the activation is negative (e.g. the neuron gets only small values and there is a huge negative bias weight), the neuron will appear dead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain the difference between: stochastic gradient descent (SGD), mini-batch SGD and regular gradient descent (GD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "All three gradient descent methods go through the same steps iteratively: forward pass, calculate loss, backward pass (Calculate grads), optimizer step (Update parameters).  The main differences:\n",
    "- SGD - run the entire cycle above for each and every sample separately.   It converges much faster than regular GD, and tends to be much more \"Jumpy\", because the optimizer takes longer and noisier path to the optimum.\n",
    "- Mini-batch SGD - run the entire cycle above per mini batch, which is a subset of the training data (More than one sample, but not all of it).   It generally converges faster than regular GD (With reasonable number of samples per batch) and is less jumpy than the SGD, because the gradients are averaged over several samples.\n",
    "- Regular GD - run the above cycle per the entire train dataset every time.    Slow, because every optiizer step requires going through the entire training set, much smoother optimizer path than SGD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Regarding SGD and GD:\n",
    "  1. Provide at least two reasons for why SGD is used more often in practice compared to GD.\n",
    "  2. In what cases can GD not be used at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Two reasons SGD is used more often than GD:\n",
    "- Regular GD requires to go over all samples to calculate the gradients, which requires much memory and is sometimes unrealistic\n",
    "- SGD Converges much faster because every sample leads to an optimization step, so even of the path is longer and noisier, it happens faster in terms of runtime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You have trained a deep resnet to obtain SoTA results on ImageNet.\n",
    "While training using mini-batch SGD with a batch size of $B$, you noticed that your model converged to a loss value of $l_0$ within $n$ iterations (batches across all epochs) on average.\n",
    "Thanks to your amazing results, you secure funding for a new high-powered server with GPUs containing twice the amount of RAM.\n",
    "You're now considering to increase the mini-batch size from $B$ to $2B$.\n",
    "Would you expect the number of of iterations required to converge to $l_0$ to decrease or increase when using the new batch size? explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "- Generally speaking, I expect that the required number of iterations will decrease, because the gradients will better represent the population and if we get to the same minima, I expect it to happen in less steps and a smoother path.   \n",
    "- Need to take into account that each iteratin will require twice the amount of calculations, so the time might actually be longer (typically number of steps will not get smaller linearly with the batch size, but calculations will double).\n",
    "- Another point to notice is that GD of any kind takes us to an arbitrary minima, but changing parameters such as batch size (Especially if we move from very small batch to a bigger one) might land us in a completely different minima point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For each of the following statements, state whether they're **true or false** and explain why.<Br>\n",
    "  a. When training a neural network with SGD, every epoch we perform an optimization step for each sample in our dataset.<Br>\n",
    "  b. Gradients obtained with SGD have less variance and lead to quicker convergence compared to GD.<Br>\n",
    "  c. SGD is less likely to get stuck in local minima, compared to GD.<Br>\n",
    "  d. Training  with SGD requires more memory than with GD.<Br>\n",
    "  e. Assuming appropriate learning rates, SGD is guaranteed to converge to a local minimum, while GD is guaranteed to converge to the global minimum.<Br>\n",
    "  f. Given a loss surface with a narrow ravine (high curvature in one direction): SGD with momentum will converge more quickly than Newton's method which doesn't have momentum.<Br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**<Br>\n",
    "a. **True** - in SGD we perform step per sample, and during an epoch we run once on all train set samples.<Br>\n",
    "b. **False** - In SGD the variance between gradients is biggeer and not smaller, but the fact that we take a step per sample and not per the entire train set, even if not always in optimal direction, does lead to faster convergance.   The faster convergance is in terms of time, not steps.<br>\n",
    "c. **True** - SGD is more random, because of the high gradient variance, and can randomly avoid \"obvious\" minima that the GD will fall into.  also, running SGD several times may lead to different minimas, while GD will tend to fall to the same one because of the avaraged gradients.<Br>\n",
    "d. **False** - The opposite is true - GD requires loading the entire train to memory for a single step, while SGD allows us to load one by one or in convenient batches.<Br>\n",
    "e. **False** - there is no guarantee to get to a global minima with any gradient based technique.   SGD will be better if we want to explore different minimas by random start positions and random step sizes, but they are both led by loof function geography.<Br>\n",
    "f. **False** - Newton is a second level technique that takes into consideration the Hassian as well as the gradient and creates an L2 approximation using Taylor, so its steps are expected to be much more accurate and converge in 1-2 steps in such landscape. It does require much more computation (Hessian) per step, so it will take more time per step, but will be rapid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Bonus** (we didn't discuss this at class):  We can use bi-level optimization in the context of deep learning, by embedding an optimization problem as a layer in the network.\n",
    "  **True or false**: In order to train such a network, the inner optimization problem must be solved with a descent based method (such as SGD, LBFGS, etc).\n",
    "  Provide a mathematical justification for your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "***Yaniv - TODO*** Bonus above\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. You have trained a neural network, where each layer $l$ is represented by the mapping $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)$ for some arbitrary parametrized functions $f_l(\\cdot;\\vec{\\theta}_l)$.\n",
    "  Unfortunately while trying to break the record for the world's deepest network, you discover that you are unable to train your network with more than $L$ layers.<br>\n",
    "  A. Explain the concepts of \"vanishing gradients\", and \"exploding gradients\".<br>\n",
    "  B. How can each of these problems be caused by increased depth?<br>\n",
    "  C. Provide a numerical example demonstrating each.<br>\n",
    "  D. Assuming your problem is either of these, how can you tell which of them it is without looking at the gradient tensor(s)?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:<br>\n",
    "**A. Vanishing gradients** - A problem in which the gradients in the backpropagation process become smaller and smaller as ther progress backwards through the network layers, untill they become numerically zero (\"Vanish\").   When the gradient is zero, the optimizer step will not move on these weights and the network will not improve.<br>\n",
    "**Exploding gradients** - A problem in which the gradients in the backpropagation process become bigger and bigger as ther progress backwards through the network layers, untill they overgrow their parameter data type and become NaN (\"Explode\").  Here too, the optimizer step will not move on these weights and the network will not improve.<br>\n",
    "**B.** backpropagation is actually derivation using the chain rule.   When we multiply each layer derivative by the derivative of the previous layers in the backprop, it will, with very high probability, reach one of the two stable states as descriibed above, with no way out.   This is even worse with activation functions such as Sigmoid / TanH which cap the values in the range of $[0,1]$ or $[-1,1]$.<Br>\n",
    "**C. Vanishing grads example:** Suppose we have a layers with ReLU activation, and its input is 2000. The gradient is then: $\\dfrac{e^{-x}}{1+e^{-x}} = 4.54 \\cdot 10^{-5}$. If we multiply several such numbers we reach numeric zero.<br>\n",
    "**Exploding grads example:**  Consider a linear layer with Sigmoid activation, where the current value of the weight is 1000 and the incoming value is 0.  Then according to the chain rule the gradient will be $\\dfrac{d}{dx}( \\sigma(w \\cdot x)) = \\dfrac{d \\sigma(w \\cdot x)}{d(w \\cdot x)} \\cdot \\dfrac{dw\\cdot x}{dx} = 0.5 \\cdot 1000 = 500$.   Even with smaller values, concatenating such values together create large gradient, that in turn trigger big steps by the optimizer that create even larger gradients, until it reaches numeric overflow and grad. explosion.<Br>\n",
    "**D.** Vanishing gradients will behave as a decay of the weight chanages and a decay of the loss improvement to a halt.<Br>\n",
    "    In Gradient explosion, we will see the weights (And probably the loss too) jumping up and down with higher and higher variance till complete halt when they explode.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You wish to train the following 2-layer MLP for a binary classification task:\n",
    "  $$\n",
    "  \\hat{y}^{(i)} =\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2\n",
    "  $$\n",
    "  Your wish to minimize the in-sample loss function is defined as\n",
    "  $$\n",
    "  L_{\\mathcal{S}} = \\frac{1}{N}\\sum_{i=1}^{N}\\ell(y^{(i)},\\hat{y}^{(i)}) + \\frac{\\lambda}{2}\\left(\\norm{\\mat{W}_1}_F^2 + \\norm{\\mat{W}_2}_F^2 \\right)\n",
    "  $$\n",
    "  Where the pointwise loss is binary cross-entropy:\n",
    "  $$\n",
    "  \\ell(y, \\hat{y}) =  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})\n",
    "  $$\n",
    "  \n",
    "  Write an analytic expression for the derivative of the final loss $L_{\\mathcal{S}}$ w.r.t. each of the following tensors: $\\mat{W}_1$, $\\mat{W}_2$, $\\mat{b}_1$, $\\mat{b}_2$, $\\mat{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "This is a derivative of a combined function, done using the chain rule.<Br>\n",
    "Lets define: $ z = \\mat{W}_1 x + b_1 $ <Br>\n",
    "<Br>\n",
    "First differentiate the inner function z:<Br>\n",
    "$$ {{\\partial z} \\over {\\partial \\mat{W}_1}} = x, \\qquad {{\\partial z} \\over {\\partial x}} = \\mat{W}_1, \\qquad {{\\partial z} \\over {\\partial b_1}} = 1 $$\n",
    "<Br>\n",
    "\n",
    "Now differentiate the pointwise loss $\\ell$ w.r.t. $\\hat{y}$:\n",
    "$$ {{\\partial \\ell} \\over {\\partial \\hat{y}}} = {{-y} \\over \\hat{y}} + {{1-y} \\over {1 -\\hat{y}}} = {{\\hat{y} - {y}} \\over {\\hat{y}(1- \\hat{y})}} $$ <Br>\n",
    "<Br>\n",
    "Since we don't know what $\\varphi$ is, we'll mark its derivative w.r.t. $z$ as: \n",
    "$$ {{\\partial \\varphi(z)} \\over {\\partial z}} = \\varphi '(z)$$<Br>\n",
    "<Br>\n",
    "And now with the chain rule:<Br>\n",
    "$$\n",
    "{{\\partial L_s} \\over {\\partial x}} =\n",
    "{{\\partial \\ell} \\over {\\partial \\hat{y}}} * \n",
    "{{\\partial \\hat{y}} \\over {\\partial z}} *\n",
    "{{\\partial z} \\over {\\partial x}} = \n",
    "{1 \\over N }\\sum_{i=1}^N{{\\hat{y} - \\mat{y}} \\over {\\hat{y}(1- \\hat{y})}} \\cdot\n",
    "\\mat{W}_2 \\cdot \\varphi ' (z) \\cdot \\mat{W}_1\n",
    "$$\n",
    "\n",
    "$$ \n",
    "{{\\partial L_s} \\over {\\partial \\mat{W}_1}} = {{\\partial \\ell} \\over {\\partial \\hat{y}}} * \n",
    "{{\\partial \\hat{y}} \\over {\\partial z}} * \n",
    "{{\\partial z} \\over {\\partial \\mat{W}_1}} +\\lambda  \\norm{\\mat{W}_1}_F = \n",
    "{1 \\over N }\\sum_{i=1}^N{{\\hat{y} - \\mat{y}} \\over {\\hat{y}(1- \\hat{y})}} \\cdot\n",
    "\\mat{W}_2 \\cdot \\varphi ' (z) \\cdot x + \\lambda  \\norm{\\mat{W}_1} _F\n",
    "$$\n",
    "\n",
    "$$\n",
    "{{\\partial L_s} \\over {\\partial \\mat{W}_2}} = \n",
    "{{\\partial \\ell} \\over {\\partial \\hat{y}}} * \n",
    "{{\\partial \\hat{y}} \\over {\\partial \\mat{W}_2}} +\n",
    "\\lambda  \\norm{\\mat{W}_2}_F = \n",
    "{1 \\over N }\\sum_{i=1}^N{{\\hat{y} - \\mat{y}} \\over {\\hat{y}(1- \\hat{y})}} \\cdot\n",
    "\\varphi(z) + \\lambda  \\norm{\\mat{W}_2}_F\n",
    "$$\n",
    "\n",
    "$$\n",
    "{{\\partial L_s} \\over {\\partial b_1}} = \n",
    "{{\\partial \\ell} \\over {\\partial \\hat{y}}} * \n",
    "{{\\partial \\hat{y}} \\over {\\partial z}} *\n",
    "{{\\partial z} \\over {\\partial b_1}} =\n",
    "{1 \\over N }\\sum_{i=1}^N{{\\hat{y} - \\mat{y}} \\over {\\hat{y}(1- \\hat{y})}} \\cdot\n",
    "\\mat{W}_2 \\cdot \\varphi '(z)\n",
    "$$\n",
    "\n",
    "$$\n",
    "{{\\partial L_s} \\over {\\partial b_2}} =\n",
    "{{\\partial \\ell} \\over {\\partial \\hat{y}}} * \n",
    "{{\\partial \\hat{y}} \\over {\\partial b_2}} = \n",
    "{1 \\over N }\\sum_{i=1}^N{{\\hat{y} - \\mat{y}} \\over {\\hat{y}(1- \\hat{y})}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The derivative of a function $f(\\vec{x})$ at a point $\\vec{x}_0$ is\n",
    "  $$\n",
    "  f'(\\vec{x}_0)=\\lim_{\\Delta\\vec{x}\\to 0} \\frac{f(\\vec{x}_0+\\Delta\\vec{x})-f(\\vec{x}_0)}{\\Delta\\vec{x}}\n",
    "  $$\n",
    "  \n",
    "  1. Explain how this formula can be used in order to compute gradients of neural network parameters numerically, without automatic differentiation (AD).\n",
    "  \n",
    "  2. What are the drawbacks of this approach? List at least two drawbacks compared to AD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**<Br>\n",
    "**Numerical differentiation** is a way to approximate the derivative of a function in a given point by calculating the function value around the point and using the derivative definition above.<Br>\n",
    "Note that the above formula is for a one-sided derivative, it is sometimes better to use 2 sided epsilons and use that to calculate the gradient, especially when it comes to optimums, where the one-sided derivatives have opposing signs. with that said, this option is more expensive because it requires more calculations.\n",
    "The two sided numeric derivative formula (Assuming $f(\\vec x)$ is smooth in point $\\vec x_0$) is:<Br>\n",
    "    <Br>\n",
    "$$\n",
    "f'(\\vec{x}_0)=\\lim_{\\Delta\\vec{x}\\to 0} \\frac{f(\\vec{x}_0+\\dfrac{\\Delta\\vec{x}}{2})-f(\\vec{x}_0 - \\dfrac{\\Delta\\vec{x}}{2})}{\\Delta\\vec{x}}\n",
    " $$\n",
    "**Algorithm** (using the two-sided formula):<Br>\n",
    "1. Choose a small value for $\\epsilon$, e.g. $\\qquad \\epsilon = 1\\mathrm{e}{-8}$\n",
    "2. Compute the function values in the points $f(\\vec{x}_0+\\dfrac{\\Delta\\vec{x}}{2})$ and $f(\\vec{x}_0-\\dfrac{\\Delta\\vec{x}}{2})$ (In the two-sided option) or $f(\\vec{x}_0+\\Delta\\vec{x})$ (in the one sided option)\n",
    "3. Use use in the formula and get an approvimarted derivative in the point $\\vec{x_0}$\n",
    "\n",
    "**Drawbacks**:\n",
    "1. Computatinally expensive $O(n)$ - need to calculate $f(\\vec x_0)$ and $f(\\vec x_0 + \\Delta x)$ (And possibly $f(\\vec x_0 - \\Delta x)$ in the double sided case) for every point instead of only once\n",
    "2. Accuracy - for large $\\vec x_0$ values - mix of large values and very small deltas could challange the floating point variables and lead to numerical accuracy issues.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Given the following code snippet:\n",
    "  1. Write a short snippet that implements that calculates gradient of `loss` w.r.t. `W` and `b` using the approach of numerical gradients from the previous question.\n",
    "  2. Calculate the same derivatives with autograd.\n",
    "  3. Show, by calling `torch.allclose()` that your numerical gradient is close to autograd's gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=tensor(1.4995, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N, d = 100, 5\n",
    "dtype = torch.float64\n",
    "X = torch.rand(N, d, dtype=dtype)\n",
    "W, b = torch.rand(d, d, requires_grad=True, dtype=dtype), torch.rand(d, requires_grad=True, dtype=dtype)\n",
    "\n",
    "def foo(W, b):\n",
    "    return torch.mean(X @ W + b)\n",
    "\n",
    "loss = foo(W, b)\n",
    "print(f\"{loss=}\")\n",
    "\n",
    "#------------------------------\n",
    "# TODO: Calculate gradients numerically for W and b\n",
    "# One sided differentiation\n",
    "epsilon = 1e-8\n",
    "\n",
    "grad_W = torch.zeros_like(W)\n",
    "grad_b = torch.zeros_like(b)\n",
    "\n",
    "for i in range(d):\n",
    "    for j in range(d):\n",
    "        W_delta = torch.clone(W)\n",
    "        W_delta[i][j] = W[i][j] + epsilon\n",
    "        loss_delta = foo(W_delta, b) \n",
    "        grad_W[i][j] = (loss_delta - loss) / epsilon\n",
    "        W_delta[i][j] = W[i][j]\n",
    "\n",
    "for i in range(d):\n",
    "    b_delta = torch.clone(b)\n",
    "    b_delta[i] = b[i] + epsilon\n",
    "    loss_delta = foo(W, b_delta)\n",
    "    grad_b[i] = (loss_delta - loss) / epsilon\n",
    "    b_delta[i] = b[i]\n",
    "\n",
    "# TODO: Compare with autograd using torch.allclose()\n",
    "loss.backward()\n",
    "autograd_W = W.grad\n",
    "autograd_b = b.grad\n",
    "\n",
    "# print(grad_W - autograd_W)\n",
    "# print(grad_b - autograd_b)\n",
    "\n",
    "assert torch.allclose(grad_W, autograd_W)\n",
    "assert torch.allclose(grad_b, autograd_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regarding word embeddings:\n",
    "  1. Explain this term and why it's used in the context of a language model.\n",
    "  1. Can a language model like the sentiment analysis example from the tutorials be trained without an embedding (i.e. trained directly on sequences of tokens)? If yes, what would be the consequence for the trained model? if no, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:<Br>\n",
    "1.  The term word embedding means mapping the tokenized words from the original token space (High dimentional - e.g. one-hot) to a more dense representation space in which the axes of the space have some meaning related to wor semantics, e.g. subject, gender, sentiment etc., so that related words are closer to each other on the relevant axes.   Word embeddings are typically used as a first step in word related task models (Sentiment analysis, generation, interprestation etc.), and are not unique for a specific task, because any language related task (Classification generation etc.) is easier with vector representation in a space that consists of meaningful axes, and these axes are typically shared between all language related tasks (Because the language is what it is, regardless of the task at hand).\n",
    "2. Yes, a language model (Like sentiment analysis) can be trained on one-hot, without meanngful embedding.\n",
    "In order for it to work well, it will need to be more complex and deep, and will require much more train data, and will probably yeild lss optimal results.<Br>\n",
    "The reason for this is that it will need to create its own hidden inherent \"embedding\" in the same time it trains on the main task of extracting meaning from the sentances (RNN of some type) and classification (Sentiment prediction).\n",
    "This instead of using \"Pre-embeddid\" representation that already has this data in one or more of its axes.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Considering the following snippet, explain:\n",
    "  1. What does `Y` contain? why this output shape?\n",
    "  2. **Bonus**: How you would implement `nn.Embedding` yourself using only torch tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape=torch.Size([5, 6, 7, 8, 42000])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "X = torch.randint(low=0, high=42, size=(5, 6, 7, 8))\n",
    "embedding = nn.Embedding(num_embeddings=42, embedding_dim=42000)\n",
    "Y = embedding(X)\n",
    "print(f\"{Y.shape=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "****I am here****\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Regarding truncated backpropagation through time (TBPTT) with a sequence length of S: State whether the following sentences are **true or false**, and explain.\n",
    "  1. TBPTT uses a modified version of the backpropagation algorithm.\n",
    "  2. To implement TBPTT we only need to limit the length of the sequence provided to the model to length S.\n",
    "  3. TBPTT allows the model to learn relations between input that are at most S timesteps apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In tutorial 5 we learned how to use attention to perform alignment between a source and target sequence in machine translation.\n",
    "  1. Explain qualitatively what the addition of the attention mechanism between the encoder and decoder does to the hidden states that the encoder and decoder each learn to generate (for their language). How are these hidden states different from the model without attention?\n",
    "  \n",
    "  2. After learning that self-attention is gaining popularity thanks to the transformer models, you decide to change the model from the tutorial: instead of the queries being equal to the decoder hidden states, you use self-attention, so that the keys, queries and values are all equal to the encoder's hidden states (with learned projections, like in the tutorial..). What influence do you expect this will have on the learned hidden states?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As we have seen, a variational autoencoder's loss is comprised of a reconstruction term and  a KL-divergence term. While training your VAE, you accidentally forgot to include the KL-divergence term.\n",
    "What would be the qualitative effect of this on:\n",
    "\n",
    "  1. Images reconstructed by the model during training ($x\\to z \\to x'$)?\n",
    "  1. Images generated by the model ($z \\to x'$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Regarding VAEs, state whether each of the following statements is **true or false**, and explain:\n",
    "  1. The latent-space distribution generated by the model for a specific input image is $\\mathcal{N}(\\vec{0},\\vec{I})$.\n",
    "  2. If we feed the same image to the encoder multiple times, then decode each result, we'll get the same reconstruction.\n",
    "  3. Since the real VAE loss term is intractable, what we actually minimize instead is it's upper bound, in the hope that the bound is tight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Regarding GANs, state whether each of the following statements is **true or false**, and explain:\n",
    "  1. Ideally, we want the generator's loss to be low, and the discriminator's loss to be high so that it's fooled well by the generator.\n",
    "  2. It's crucial to backpropagate into the generator when training the discriminator.\n",
    "  3. To generate a new image, we can sample a latent-space vector from $\\mathcal{N}(\\vec{0},\\vec{I})$.\n",
    "  4. It can be beneficial for training the generator if the discriminator is trained for a few epochs first, so that it's output isn't arbitrary.\n",
    "  5. If the generator is generating plausible images and the discriminator reaches a stable state where it has 50% accuracy (for both image types), training the generator more will further improve the generated images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection and Segmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the diffrence between IoU and Dice score? what's the diffrance between IoU and mAP?\n",
    "    shortly explain when would you use what evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. regarding of YOLO and mask-r-CNN, witch one is one stage detector? describe the RPN outputs and the YOLO output, adress how the network produce the output and the shapes of each output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
